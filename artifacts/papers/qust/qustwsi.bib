@article{Wang:2017,
abstract = {Identification of patients with early stage non-small cell lung cancer (NSCLC) with high risk of recurrence could help identify patients who would receive additional benefit from adjuvant therapy. In this work, we present a computational histomorphometric image classifier using nuclear orientation, texture, shape, and tumor architecture to predict disease recurrence in early stage NSCLC from digitized H\&E tissue microarray (TMA) slides. Using a retrospective cohort of early stage NSCLC patients (Cohort #1, n = 70), we constructed a supervised classification model involving the most predictive features associated with disease recurrence. This model was then validated on two independent sets of early stage NSCLC patients, Cohort #2 (n = 119) and Cohort #3 (n = 116). The model yielded an accuracy of 81\% for prediction of recurrence in the training Cohort #1, 82\% and 75\% in the validation Cohorts #2 and #3 respectively. A multivariable Cox proportional hazard model of Cohort #2, incorporating gender and traditional prognostic variables such as nodal status and stage indicated that the computer extracted histomorphometric score was an independent prognostic factor (hazard ratio = 20.81, 95\% CI: 6.42-67.52, P < 0.001).},
author = {Xiangxue Wang and Andrew Janowczyk and Yu Zhou and Rajat Thawani and Pingfu Fu and Kurt Schalper and others},
doi = {10.1038/s41598-017-13773-7},
isbn = {4159801713773},
issn = {20452322},
issue = {1},
journal = {Scientific Reports},
pmid = {29051570},
title = {Prediction of recurrence in early stage non-small cell lung cancer using computer extracted nuclear features from digital H\&E images},
volume = {7},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19420234 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2680097 http://www.ncbi.nlm.nih.gov/pubmed/29051570 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5648794},
year = {2017},
}


@article{Webster:2009,
abstract = {The nucleus is one of the most prominent cellular organelles, yet surprisingly little is known about how it is formed, what determines its shape and what defines its size. As the nuclear envelope (NE) disassembles in each and every cell cycle in metazoans, the process of rebuilding the nucleus is crucial for proper development and cell proliferation. In this Commentary, we summarize what is known about the regulation of nuclear shape and size, and highlight recent findings that shed light on the process of building a nucleus, including new discoveries related to NE assembly and the relationship between the NE and the endoplasmic reticulum (ER). Throughout our discussion, we note interesting aspects of nuclear structure that have yet to be resolved. Finally, we present an idea - which we refer to as ;the limited flat membrane hypothesis' - to explain the formation of a single nucleus that encompasses of all of the cell's chromosomes following mitosis.},
author = {Micah Webster and Keren L Witkin and Orna Cohen-Fix},
doi = {10.1242/jcs.037333},
issn = {0021-9533},
issue = {Pt 10},
journal = {Journal of Cell Science},
month = {5},
pages = {1477-86},
pmid = {19420234},
publisher = {Company of Biologists},
title = {Sizing up the nucleus: nuclear shape, size and nuclear-envelope assembly.},
volume = {122},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19420234 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2680097},
year = {2009},
}


@article{Makhzani:2013,
author = {Alireza Makhzani and Brendan Frey},
journal = {ArXiv: Learning (cs.LG)},
keywords = {(),Computer Science - Learning},
month = {12},
title = {k-sparse autoencoders},
url = {http://arxiv.org/abs/1312.5663},
year = {2013},
}


@article{Pantanowitz:2010,
author = {Liron Pantanowitz},
doi = {10.4103/2153-3539.68332},
issn = {2153-3539},
journal = {Journal of Pathology Informatics},
month = {8},
pmid = {20922032},
publisher = {Wolters Kluwer -- Medknow Publications},
title = {Digital images and the future of digital pathology.},
volume = {1},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20922032 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2941968},
year = {2010},
}


@inproceedings{Huang:2017,
author = {Chao-Hui Huang and Daniel Racoceanu},
doi = {10.1117/12.2253642},
editor = {Metin N. Gurcan and John E. Tomaszewski},
month = {3},
pages = {101400A},
title = {Automated high-grade prostate cancer detection and ranking on whole slide images},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2253642},
year = {2017},
}


@inproceedings{Huang:2018a,
author = {Chao-Hui Huang and Jens Brodbeck and Nena M. Dimaano and Douglas Rollins and Belma Dogdas and Eric M. Gifford},
journal = {1 Page Abstract at the IEEE International Symposium on Biomedical Imaging (ISBI)},
title = {Open-remote-slide: remote access solution for more efficient automated pathological analytics},
year = {2018},
}


@article{Howell:2014,
abstract = {Breast cancer is an increasing public health problem. Substantial advances have been made in the treatment of breast cancer, but the introduction of methods to predict women at elevated risk and prevent the disease has been less successful. Here, we summarize recent data on newer approaches to risk prediction, available approaches to prevention, how new approaches may be made, and the difficult problem of using what we already know to prevent breast cancer in populations. During 2012, the Breast Cancer Campaign facilitated a series of workshops, each covering a specialty area of breast cancer to identify gaps in our knowledge. The risk-and-prevention panel involved in this exercise was asked to expand and update its report and review recent relevant peer-reviewed literature. The enlarged position paper presented here highlights the key gaps in risk-and-prevention research that were identified, together with recommendations for action. The panel estimated from the relevant literature that potentially 50\% of breast cancer could be prevented in the subgroup of women at high and moderate risk of breast cancer by using current chemoprevention (tamoxifen, raloxifene, exemestane, and anastrozole) and that, in all women, lifestyle measures, including weight control, exercise, and moderating alcohol intake, could reduce breast cancer risk by about 30\%. Risk may be estimated by standard models potentially with the addition of, for example, mammographic density and appropriate single-nucleotide polymorphisms. This review expands on four areas: (a) the prediction of breast cancer risk, (b) the evidence for the effectiveness of preventive therapy and lifestyle approaches to prevention, (c) how understanding the biology of the breast may lead to new targets for prevention, and (d) a summary of published guidelines for preventive approaches and measures required for their implementation. We hope that efforts to fill these and other gaps will lead to considerable advances in our efforts to predict risk and prevent breast cancer over the next 10 years.},
author = {Anthony Howell and Annie S Anderson and Robert B Clarke and Stephen W Duffy and D Gareth Evans and Montserat Garcia-Closas and others},
doi = {10.1186/s13058-014-0446-2},
issn = {1465-542X},
issue = {5},
journal = {Breast Cancer Research},
month = {10},
pages = {446},
pmid = {25467785},
title = {Risk determination and prevention of breast cancer},
volume = {16},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25467785 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4303126 http://breast-cancer-research.biomedcentral.com/articles/10.1186/s13058-014-0446-2},
year = {2014},
}


@article{Jorgensen:2017,
abstract = {Currently, diagnosis of colon cancer is based on manual examination of histopathological images by a pathologist. This can be time consuming and interpretation of the images is subject to inter- and intra-observer variability. This may be improved by introducing a computer-aided diagnosis (CAD) system for automatic detection of cancer tissue within whole slide hematoxylin and eosin (H\&E) stains. Cancer disrupts the normal control mechanisms of cell proliferation and differentiation, affecting the structure and appearance of the cells. Therefore, extracting features from segmented cell nuclei structures may provide useful information to detect cancer tissue. A framework for automatic classification of regions of interest (ROI) containing either benign or cancerous colon tissue extracted from whole slide H\&E stained images using cell nuclei features was proposed. A total of 1,596 ROI's were extracted from 87 whole slide H\&E stains (44 benign and 43 cancer). A cell nuclei segmentation algorithm consisting of color deconvolution, k-means clustering, local adaptive thresholding, and cell separation was performed within the ROI's to extract cell nuclei features. From the segmented cell nuclei structures a total of 750 texture and intensity-based features were extracted for classification of the ROI's. The nine most discriminative cell nuclei features were used in a random forest classifier to determine if the ROI's contained benign or cancer tissue. The ROI classification obtained an area under the curve (AUC) of 0.96, sensitivity of 0.88, specificity of 0.92, and accuracy of 0.91 using an optimized threshold. The developed framework showed promising results in using cell nuclei features to classify ROIs into containing benign or cancer tissue in H\&E stained tissue samples. © 2017 International Society for Advancement of Cytometry.},
author = {Alex S. J\c{o}rgensen and Anders M. Rasmussen and Niels K. M. Andersen and Simon K. Andersen and Jonas Emborg and Rasmus R\c{o}ge and others},
doi = {10.1002/cyto.a.23175},
issn = {15524922},
issue = {8},
journal = {Cytometry Part A},
keywords = {H\&E stain,cancer,cell segmentation,classification,colon,image analysis},
month = {8},
pages = {785-793},
pmid = {28727286},
title = {Using cell nuclei features to detect colon cancer tissue in hematoxylin and eosin stained slides},
volume = {91},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28727286 http://doi.wiley.com/10.1002/cyto.a.23175},
year = {2017},
}


@article{Xu:2016,
abstract = {Automated nuclear detection is a critical step for a number of computer assisted pathology related image analysis algorithms such as for automated grading of breast cancer tissue specimens. The Nottingham Histologic Score system is highly correlated with the shape and appearance of breast cancer nuclei in histopathological images. However, automated nucleus detection is complicated by 1) the large number of nuclei and the size of high resolution digitized pathology images, and 2) the variability in size, shape, appearance, and texture of the individual nuclei. Recently there has been interest in the application of "Deep Learning" strategies for classification and analysis of big image data. Histopathology, given its size and complexity, represents an excellent use case for application of deep learning strategies. In this paper, a Stacked Sparse Autoencoder (SSAE), an instance of a deep learning strategy, is presented for efficient nuclei detection on high-resolution histopathological images of breast cancer. The SSAE learns high-level features from just pixel intensities alone in order to identify distinguishing features of nuclei. A sliding window operation is applied to each image in order to represent image patches via high-level features obtained via the auto-encoder, which are then subsequently fed to a classifier which categorizes each image patch as nuclear or non-nuclear. Across a cohort of 500 histopathological images (2200 × 2200) and approximately 3500 manually segmented individual nuclei serving as the groundtruth, SSAE was shown to have an improved F-measure 84.49\% and an average area under Precision-Recall curve (AveP) 78.83\%. The SSAE approach also out-performed nine other state of the art nuclear detection strategies.},
author = {Jun Xu and Lei Xiang and Qingshan Liu and Hannah Gilmore and Jianzhong Wu and Jinghai Tang and others},
doi = {10.1109/TMI.2015.2458702},
issn = {0278-0062},
issue = {1},
journal = {IEEE Transactions on Medical Imaging},
month = {1},
pages = {119-130},
pmid = {26208307},
title = {Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images},
volume = {35},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26208307 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4729702 http://ieeexplore.ieee.org/document/7163353/},
year = {2016},
}


@article{Balslev:1994,
abstract = {In primary, operable breast cancer, the Nottingham Prognostic Index (NPI) based on tumour size, lymph node stage and histological grade can identify three prognostic groups (PGs) with 10-year survival rates of 83\%, 52\%, and 13\%. With the aim of defining a subset of patients having so good prognosis that adjuvant therapy can be withhold, the NPI was applied to a Danish population-based study group comprising 9,149 patients. As opposed to the British study, we used conventional axillary lymph-node staging. Histological grading was in both studies done by means of a similar slight modification of the Bloom and Richardson procedure, but in the Danish study only ductal carcinomas were graded. The 10-year crude survival was 68.1\% for 4,791 patients with tumour size < or = 2 cm and 70.0\% for 2,900 patients with grade I tumours. For 4,761 node-negative patients, the 10-year survival was also 70.0\%, the expected survival being 89.3\%. The relative mortality (observed:expected) was even at 10 years 2.1 demonstrating that more than 10 years observation time is necessary to estimate cumulated mortality. By application of the NPI, the Danish good PG comprising 27.3\% of the patients had a 10-year survival of 79.0\%. Thus, the index defined a subset with better survival than could be defined individually by each of its three components, but it did not succeed in defining a subset with survival similar to the expected; additional prognostic factors are therefore needed. The somewhat poorer survival of the Danish good PG may be ascribed to the British inclusion of non-ductal carcinomas, to interobserver variation present only in the Danish study, and to poorer expected survival of the Danish patients. The 10-year survival of the Danish moderate PG and poor PG was 56\% and 25\%, respectively. These improved survival rates are attributed to the administration of adjuvant therapies. There were virtually no node-positive patients in the good PG and no node-negative patients in the poor PG. Patients should therefore still be stratified initially by lymph-node status, but tumour size and histological grade are significant prognostic factors primarily within the node-negative group, and they should be included in future prognostication procedures.},
author = {Ingegerd Balslev and Christen K. Axelsson and Karin Zedeler and Birgitte B. Rasmussen and Bendix Carstensen and Henning T. Mouridsen},
doi = {10.1007/BF00666005},
isbn = {0167-6806 (Print)\r0167-6806 (Linking)},
issn = {01676806},
issue = {3},
journal = {Breast Cancer Research and Treatment},
keywords = {breast cancer,histological grade,lymph-node staging,multivariate prognostic index,prognostic factors,survival,tumour size},
pages = {281-290},
pmid = {7865856},
title = {The Nottingham prognostic index applied to 9,149 patients from the studies of thedanish breast cancer cooperative group (DBCG)},
volume = {32},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7865856},
year = {1994},
}


@book{Rumelhart:1986,
abstract = {The fundamental principles, basic mechanisms, and formal analyses involved in the development of parallel distributed processing (PDP) systems are presented in individual chapters contributed by leading experts. Topics examined include distributed representations, PDP models and general issues in cognitive science, feature discovery by competitive learning, the foundations of harmony theory, learning and relearning in Boltzmann machines, and learning internal representations by error propagation. Consideration is given to linear algebra in PDP, the logic of additive functions, resource requirements of standard and programmable nets, and the P3 parallel-network simulating system. Parallel distributed processing:... (PDF Download Available). Available from: https://www.researchgate.net/publication/200033859_Parallel_distributed_processing_explorations_in_the_microstructure_of_cognition_Volume_1_Foundations [accessed May 03 2018].},
author = {David E. Rumelhart and James L. McClelland and PDP Research Group},
isbn = {026268053X},
journal = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol. 1},
pages = {318-362},
publisher = {MIT Press, Cambridge, Massachusetts},
title = {Parallel distributed processing : explorations in the microstructure of cognition},
url = {https://dl.acm.org/citation.cfm?id=104293},
year = {1986},
}


@article{Hinton:2006a,
abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
author = {Geoffrey E. Hinton and Ruslan Salakhutdinov},
doi = {10.1126/science.1127647},
issn = {0036-8075},
issue = {5786},
journal = {Science},
month = {7},
pages = {504-507},
pmid = {16873662},
title = {Reducing the dimensionality of data with neural networks},
volume = {313},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16873662 http://www.sciencemag.org/cgi/doi/10.1126/science.1127647},
year = {2006},
}


@article{Hinton:2006b,
abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
author = {Geoffrey E. Hinton and Simon Osindero and Yee-Whye Teh},
doi = {10.1162/neco.2006.18.7.1527},
issn = {0899-7667},
issue = {7},
journal = {Neural Computation},
month = {7},
pages = {1527-1554},
pmid = {16764513},
title = {A fast learning algorithm for deep belief nets},
volume = {18},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513 http://www.mitpressjournals.org/doi/10.1162/neco.2006.18.7.1527},
year = {2006},
}


@misc{MNISTHandwrittenDigitDatabase,
author = {Yann LeCun and Corinna Cortes and Christopher J. C. Burges},
title = {MNIST Handwritten Digit Database},
url = {http://yann.lecun.com/exdb/mnist/},
}


@inproceedings{Huang:2015,
author = {Chao-Hui Huang},
doi = {10.1109/MLSP.2015.7324359},
isbn = {978-1-4673-7454-5},
journal = {2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)},
month = {9},
pages = {1-6},
publisher = {IEEE},
title = {Semi-supervised color decomposition for histopathological images using exclusive component analysis},
url = {http://ieeexplore.ieee.org/document/7324359/},
year = {2015},
}


@inproceedings{Macenko:2009,
author = {Marc Macenko and Marc Niethammer and J. S. Marron and David Borland and John T. Woosley and Xiaojun Guan and others},
doi = {10.1109/ISBI.2009.5193250},
isbn = {978-1-4244-3931-7},
journal = {2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro},
month = {6},
pages = {1107-1110},
publisher = {IEEE},
title = {A method for normalizing histology slides for quantitative analysis},
url = {http://ieeexplore.ieee.org/document/5193250/},
year = {2009},
}


@article{Reinhard:2001,
author = {E. Reinhard and M. Adhikhmin and B. Gooch and P. Shirley},
doi = {10.1109/38.946629},
issn = {02721716},
issue = {4},
journal = {IEEE Computer Graphics and Applications},
pages = {34-41},
title = {Color transfer between images},
volume = {21},
url = {http://ieeexplore.ieee.org/document/946629/},
year = {2001},
}


@inproceedings{Zanijai:2018,
author = {Farhad Ghazvinian Zanijai and Svitlana Zinger and Babak Ehteshami Bejnordi and Jeroen A. W. M van der Laak and Peter H. N. de With},
journal = {Proceedings of EEE International Symposium on Biomedical Imaging (ISBI'18)},
title = {Stain Normalization of Histopathology Images using Generative Adversarial Networks},
year = {2018},
}


@article{Irshad:2014,
author = {H. Irshad and A. Veillard and L. Roux and D. Racoceanu},
journal = {IEEE Reviews on Biomedical Engineering},
pages = {97-114},
title = {Methods for Nuclei Detection, Segmentation, and Classification in Digital Histopathology: A Review — Current Status and Future Potential},
volume = {7},
year = {2014},
}


@article{Sirinukunwattana:2016,
author = {Korsuk Sirinukunwattana and Shan E Ahmed Raza and Yee-Wah Tsang and David R. J. Snead and Ian A. Cree and Nasir M. Rajpoot},
doi = {10.1109/TMI.2016.2525803},
issn = {0278-0062},
issue = {5},
journal = {IEEE Transactions on Medical Imaging},
month = {5},
pages = {1196-1206},
title = {Locality Sensitive Deep Learning for Detection and Classification of Nuclei in Routine Colon Cancer Histology Images},
volume = {35},
url = {http://ieeexplore.ieee.org/document/7399414/},
year = {2016},
}


@article{Huang:2011,
author = {Chao-Hui Huang and others},
issue = {7-8},
journal = {CMIG, Elsevier},
pages = {579-591},
title = {Time-efficient sparse analysis of histopathological Whole Slide Images},
volume = {35},
year = {2011},
}


@article{Khan:2014,
author = {Adnan Mujahid Khan and others},
issue = {6},
journal = {IEEE Trans. Biomed. Eng.},
pages = {1729-1738},
title = {A nonlinear mapping approach to stain normalization in digital histopathology images using image-specific color deconvolution},
volume = {61},
year = {2014},
}


@article{Ciompi:2017,
abstract = {The development of reliable imaging biomarkers for the analysis of colorectal cancer (CRC) in hematoxylin and eosin (H\&E) stained histopathology images requires an accurate and reproducible classification of the main tissue components in the image. In this paper, we propose a system for CRC tissue classification based on convolutional networks (ConvNets). We investigate the importance of stain normalization in tissue classification of CRC tissue samples in H\&E-stained images. Furthermore, we report the performance of ConvNets on a cohort of rectal cancer samples and on an independent publicly available dataset of colorectal H\&E images.},
author = {Francesco Ciompi and Oscar Geessink and Babak Ehteshami Bejnordi and Gabriel Silva de Souza and Alexi Baidoshvili and Geert Litjens and others},
journal = {ArXiv: Computer Vision and Pattern Recognition (cs.CV)},
month = {2},
title = {The importance of stain normalization in colorectal tissue classification with convolutional networks},
url = {http://arxiv.org/abs/1702.05931},
year = {2017},
}


@article{Wang:2016,
abstract = {The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.},
author = {Dayong Wang and Aditya Khosla and Rishab Gargeya and Humayun Irshad and Andrew H Beck},
month = {6},
title = {Deep learning for identifying metastatic breast cancer},
url = {http://arxiv.org/abs/1606.05718},
year = {2016},
}


@article{Kang:2005,
abstract = {—This paper proposes a new method to model partially connected feedforward neural networks (PCFNNs) from the iden-tified input type (IT) which refers to whether each input is cou-pled with or uncoupled from other inputs in generating output. The identification is done by analyzing input sensitivity changes as amplifying the magnitude of inputs. The sensitivity changes of the uncoupled inputs are not correlated with the variation on any other input, while those of the coupled inputs are correlated with the variation on any one of the coupled inputs. According to the identified ITs, a PCFNN can be structured. Each uncoupled input does not share the neurons in the hidden layer with other inputs in order to contribute to output in an independent manner, while the coupled inputs share the neurons with one another. After deriving the mathematical input sensitivity analysis for each IT, several ex-periments, as well as a real example (blood pressure (BP) estima-tion), are described to demonstrate how well our method works. Index Terms—Fully connected neural network (FCNN), input sensitivity, input type (IT), partially connected neural network (PCNN).},
author = {Sanggil Kang and Can Isik},
doi = {10.1109/TNN.2004.839353},
issue = {1},
journal = {IEEE Transactions on Neural Networks},
title = {Partially connected feedforward neural networks structured by input types},
volume = {16},
url = {https://pdfs.semanticscholar.org/597b/83be3d82a027cb5a96229515005e123097be.pdf},
year = {2005},
}


@article{Erhan:2010,
author = {Dumitru Erhan and Yoshua Bengio and Aaron Courville and Pierre-Antoine Manzagol and Pascal Vincent and Samy Bengio},
issn = {ISSN 1533-7928},
issue = {Feb},
journal = {Journal of Machine Learning Research},
pages = {625-660},
title = {Why does unsupervised pre-training help deep learning?},
volume = {11},
url = {http://www.jmlr.org/papers/v11/erhan10a.html},
year = {2010},
}


@article{Janowczyk:2016,
abstract = {BACKGROUND Deep learning (DL) is a representation learning approach ideally suited for image analysis challenges in digital pathology (DP). The variety of image analysis tasks in the context of DP includes detection and counting (e.g., mitotic events), segmentation (e.g., nuclei), and tissue classification (e.g., cancerous vs. non-cancerous). Unfortunately, issues with slide preparation, variations in staining and scanning across sites, and vendor platforms, as well as biological variance, such as the presentation of different grades of disease, make these image analysis tasks particularly challenging. Traditional approaches, wherein domain-specific cues are manually identified and developed into task-specific "handcrafted" features, can require extensive tuning to accommodate these variances. However, DL takes a more domain agnostic approach combining both feature discovery and implementation to maximally discriminate between the classes of interest. While DL approaches have performed well in a few DP related image analysis tasks, such as detection and tissue classification, the currently available open source tools and tutorials do not provide guidance on challenges such as (a) selecting appropriate magnification, (b) managing errors in annotations in the training (or learning) dataset, and (c) identifying a suitable training set containing information rich exemplars. These foundational concepts, which are needed to successfully translate the DL paradigm to DP tasks, are non-trivial for (i) DL experts with minimal digital histology experience, and (ii) DP and image processing experts with minimal DL experience, to derive on their own, thus meriting a dedicated tutorial. AIMS This paper investigates these concepts through seven unique DP tasks as use cases to elucidate techniques needed to produce comparable, and in many cases, superior to results from the state-of-the-art hand-crafted feature-based classification approaches. RESULTS Specifically, in this tutorial on DL for DP image analysis, we show how an open source framework (Caffe), with a singular network architecture, can be used to address: (a) nuclei segmentation (F-score of 0.83 across 12,000 nuclei), (b) epithelium segmentation (F-score of 0.84 across 1735 regions), (c) tubule segmentation (F-score of 0.83 from 795 tubules), (d) lymphocyte detection (F-score of 0.90 across 3064 lymphocytes), (e) mitosis detection (F-score of 0.53 across 550 mitotic events), (f) invasive ductal carcinoma detection (F-score of 0.7648 on 50 k testing patches), and (g) lymphoma classification (classification accuracy of 0.97 across 374 images). CONCLUSION This paper represents the largest comprehensive study of DL approaches in DP to date, with over 1200 DP images used during evaluation. The supplemental online material that accompanies this paper consists of step-by-step instructions for the usage of the supplied source code, trained models, and input data.},
author = {Andrew Janowczyk and Anant Madabhushi},
doi = {10.4103/2153-3539.186902},
issn = {2229-5089},
issue = {1},
journal = {Journal of Pathology Informatics},
keywords = {Classification,deep learning,detection,digital histology,machine learning,segmentation},
pages = {29},
pmid = {27563488},
publisher = {Medknow Publications and Media Pvt. Ltd.},
title = {Deep learning for digital pathology image analysis: A comprehensive tutorial with selected use cases.},
volume = {7},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27563488 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4977982},
year = {2016},
}


@article{Chen:2016,
abstract = {Automatic detection of lymphocyte in H\&E images is a necessary first step in lots of tissue image analysis algorithms. An accurate and robust automated lymphocyte detection approach is of great importance in both computer science and clinical studies. Most of the existing approaches for lymphocyte detection are based on traditional image processing algorithms and/or classic machine learning methods. In the recent years, deep learning techniques have fundamentally transformed the way that a computer interprets images and have become a matchless solution in various pattern recognition problems. In this work, we design a new deep neural network model which extends the fully convolutional network by combining the ideas in several recent techniques, such as shortcut links. Also, we design a new training scheme taking the prior knowledge about lymphocytes into consideration. The training scheme not only efficiently exploits the limited amount of free-form annotations from pathologists, but also naturally supports efficient fine-tuning. As a consequence, our model has the potential of self-improvement by leveraging the errors collected during real applications. Our experiments show that our deep neural network model achieves good performance in the images of different staining conditions or different types of tissues.},
author = {Jianxu Chen and Chukka Srinivas},
journal = {ArXiv: Computer Vision and Pattern Recognition (cs.CV)},
month = {12},
title = {Automatic lymphocyte detection in h\&e images with deep neural networks},
url = {http://arxiv.org/abs/1612.03217},
year = {2016},
}


@article{Ng,
author = {Andrew Ng},
title = {CS294A lecture notes: sparse autoencoder},
url = {https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf},
}


@article{Chen:2017,
abstract = {In this work, we present a simple, highly efficient and modularized Dual Path Network (DPN) for image classification which presents a new topology of connection paths internally. By revealing the equivalence of the state-of-the-art Residual Network (ResNet) and Densely Convolutional Network (DenseNet) within the HORNN framework, we find that ResNet enables feature re-usage while DenseNet enables new features exploration which are both important for learning good representations. To enjoy the benefits from both path topologies, our proposed Dual Path Network shares common features while maintaining the flexibility to explore new features through dual path architectures. Extensive experiments on three benchmark datasets, ImagNet-1k, Places365 and PASCAL VOC, clearly demonstrate superior performance of the proposed DPN over state-of-the-arts. In particular, on the ImagNet-1k dataset, a shallow DPN surpasses the best ResNeXt-101(64x4d) with 26\% smaller model size, 25\% less computational cost and 8\% lower memory consumption, and a deeper DPN (DPN-131) further pushes the state-of-the-art single model performance with about 2 times faster training speed. Experiments on the Places365 large-scale scene dataset, PASCAL VOC detection dataset, and PASCAL VOC segmentation dataset also demonstrate its consistently better performance than DenseNet, ResNet and the latest ResNeXt model over various applications.},
author = {Yunpeng Chen and Jianan Li and Huaxin Xiao and Xiaojie Jin and Shuicheng Yan and Jiashi Feng},
month = {7},
title = {Dual path networks},
url = {http://arxiv.org/abs/1707.01629},
year = {2017},
}


@article{Khoshdeli:2017,
abstract = {Detection of nuclei is an important step in phenotypic profiling of histology sections that are usually imaged in bright field. However, nuclei can have multiple phenotypes, which are difficult to model. It is shown that convolutional neural networks (CNN)s can learn different phenotypic signatures for nuclear detection, and that the performance is improved with the feature-based representation of the original image. The feature-based representation utilizes Laplacian of Gaussian (LoG) filter, which accentuates blob-shape objects. Several combinations of input data representations are evaluated to show that by LoG representation, detection of nuclei is advanced. In addition, the efficacy of CNN for vesicular and hyperchromatic nuclei is evaluated. In particular, the frequency of detection of nuclei with the vesicular and apoptotic phenotypes is increased. The overall system has been evaluated against manually annotated nuclei and the F-Scores for alternative representations have been reported.},
author = {Mina Khoshdeli and Richard Cong and Bahram Parvin},
doi = {10.1109/BHI.2017.7897216},
journal = {IEEE-EMBS International Conference on Biomedical and Health Informatics. IEEE-EMBS International Conference on Biomedical and Health Informatics},
month = {2},
pages = {105-108},
pmid = {28580455},
publisher = {NIH Public Access},
title = {Detection of Nuclei in H\&E Stained Sections Using Convolutional Neural Networks.},
volume = {2017},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28580455 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5455148},
year = {2017},
}


@inproceedings{Baldi:2012,
abstract = {Autoencoders play a fundamental role in unsupervised learning and in deep architectures for transfer learning and other tasks. In spite of their fundamental role, only linear au- toencoders over the real numbers have been solved analytically. Here we present a general mathematical framework for the study of both linear and non-linear autoencoders. The framework allows one to derive an analytical treatment for the most non-linear autoen- coder, the Boolean autoencoder. Learning in the Boolean autoencoder is equivalent to a clustering problem that can be solved in polynomial time when the number of clusters is small and becomes NP complete when the number of clusters is large. The framework sheds light on the different kinds of autoencoders, their learning complexity, their horizontal and vertical composability in deep architectures, their critical points, and their fundamental connections},
author = {Pierre Baldi},
doi = {10.1561/2200000006},
isbn = {2200000006},
issn = {0899-7667},
journal = {The 29th International Conference on Machine Learning (ICML2012): Unsupervised and Transfer Learning},
keywords = {autoencoders,deep architectures,hebbian learning,information,unsupervised learning},
month = {6},
pages = {37-50},
pmid = {24966830},
title = {Autoencoders, unsupervised learning, and deep architectures},
url = {http://proceedings.mlr.press/v27/baldi12a.html},
year = {2012},
}


@article{Zhou:2012,
abstract = {In this paper, we propose the MIML (Multi-Instance Multi-Label learning) framework where an example is described by multiple instances and associated with multiple class labels. Compared to traditional learning frameworks, the MIML framework is more convenient and natural for representing complicated objects which have multiple semantic meanings. To learn from MIML examples, we propose the MimlBoost and MimlSvm algorithms based on a simple degeneration strategy, and experiments show that solving problems involving complicated objects with multiple semantic meanings in the MIML framework can lead to good performance. Considering that the degeneration process may lose information, we propose the D-MimlSvm algorithm which tackles MIML problems directly in a regularization framework. Moreover, we show that even when we do not have access to the real objects and thus cannot capture more information from real objects by using the MIML representation, MIML is still useful. We propose the InsDif and SubCod algorithms. InsDif works by transforming single-instances into the MIML representation for learning, while SubCod works by transforming single-label examples into the MIML representation for learning. Experiments show that in some tasks they are able to achieve better performance than learning the single-instances or single-label examples directly.},
author = {Zhi-Hua Zhou and Min-Ling Zhang and Sheng-Jun Huang and Yu-Feng Li},
doi = {10.1016/J.ARTINT.2011.10.002},
issn = {0004-3702},
issue = {1},
journal = {Artificial Intelligence},
month = {1},
pages = {2291-2320},
publisher = {Elsevier},
title = {Multi-instance multi-label learning},
volume = {176},
url = {https://www.sciencedirect.com/science/article/pii/S0004370211001123},
year = {2012},
}


@article{Ilse:2018,
abstract = {Multiple instance learning (MIL) is a variation of supervised learning where a single class label is assigned to a bag of instances. In this paper, we state the MIL problem as learning the Bernoulli distribution of the bag label where the bag label probability is fully parameterized by neural networks. Furthermore, we propose a neural network-based permutation-invariant aggregation operator that corresponds to the attention mechanism. Notably, an application of the proposed attention-based operator provides insight into the contribution of each instance to the bag label. We show empirically that our approach achieves comparable performance to the best MIL methods on benchmark MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and two real-life histopathology datasets without sacrificing interpretability.},
author = {Maximilian Ilse and Jakub M Tomczak and Max Welling},
journal = {ArXiv: Learning (cs.LG)},
month = {2},
title = {Attention-based deep multiple instance learning},
url = {http://arxiv.org/abs/1802.04712},
year = {2018},
}


@article{Rujuta:2017,
abstract = {Histological tissue section provides rich information about cellular structure. There are considerable amount of variations in cell structure, and cell organization that impede analysis of large histological dataset. This paper is a review of some recent state-of-art nucleus/cell segmentation approaches on different types of microscopic images. In the conventional diagnosis, pathologist analyze biopsies to make diagnostic assessment. Recently some automatic methods have been evolving in digital histopathology with growing application related to nuclear detection and segmentation. We and discussed and studied here various trends on nucleus detection, and segmentation.},
author = {O Rujuta and Arati J Vyavhare},
doi = {10.4172/2155-9538.1000227},
issn = {21559538},
issue = {02},
journal = {Journal of Bioengineering \& Biomedical Science},
keywords = {Digital pathology,Microscopic analysis,Nuclear detection,Nuclear segmentation},
month = {5},
pages = {--},
publisher = {OMICS International},
title = {Review of Nuclei Detection, Segmentation in Microscopic Images},
volume = {07},
url = {https://www.omicsonline.org/open-access/review-of-nuclei-detection-segmentation-in-microscopic-images-2155-9538-1000227.php?aid=90144 https://pdfs.semanticscholar.org/c182/8dd6282a2a16121f526d59628868193c1ccd.pdf},
year = {2017},
}


@article{Yuan:2012,
author = {Y. Yuan and H. Failmezger and O. M. Rueda and H. R. Ali and S. Graf and S.-F. Chin and others},
doi = {10.1126/scitranslmed.3004330},
issn = {1946-6234},
issue = {157},
journal = {Science Translational Medicine},
month = {10},
pages = {157ra143},
title = {Quantitative Image Analysis of Cellular Heterogeneity in Breast Tumors Complements Genomic Profiling},
volume = {4},
url = {http://stm.sciencemag.org/cgi/doi/10.1126/scitranslmed.3004330},
year = {2012},
}


@inproceedings{Sirinukunwattana:2015,
abstract = {The first step prior to most analyses on most histopathology images is the detection of area of interest. In this work, we present a superpixel-based approach for glandular structure detection in colon histology images. An image is first segmented into superpixels with the constraint on the presence of glandular boundaries. Texture and color information is then extracted from each superpixel to calculate the probability of that superpixel belonging to glandular regions, resulting in a glandular probability map. In addition, we present a novel texture descriptor derived from a region covariance matrix of scattering coefficients. Our approach shows encouraging results for the detection of glandular structures in colon tissue samples.},
author = {Korsuk Sirinukunwattana and David R. Snead and Nasir M. Rajpoot},
doi = {10.1117/12.2082010},
editor = {Metin N. Gurcan and Anant Madabhushi},
keywords = {colon histology image,epithelial gland,gland segmentation,supperpixel,texture descriptor},
month = {3},
pages = {94200S},
publisher = {International Society for Optics and Photonics},
title = {A novel texture descriptor for detection of glandular structures in colon histology images},
volume = {9420},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2082010},
year = {2015},
}


@misc{IndependentComponentAnalysis:AlgorithmsandApplications,
abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of nongaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject. 1 Motivation Imagine that you are in a room where two people are speaking simultaneously. You have two microphones, which you hold in different locations. The microphones give you two recorded time signals, which we could denote by x 1 (t) and x 2 (t), with x 1 and x 2 the amplitudes, and t the time index. Each of these recorded signals is a weighted sum of the speech signals emitted by the two speakers, which we denote by s 1 (t) and s 2 (t). We could express this as a linear equation: x 1 (t) = a 11 s 1 + a 12 s 2 (1) x 2 (t) = a 21 s 1 + a 22 s 2 (2) where a 11 , a 12 , a 21 , and a 22 are some parameters that depend on the distances of the microphones from the speakers. It would be very useful if you could now estimate the two original speech signals s 1 (t) and s 2 (t), using only the recorded signals x 1 (t) and x 2 (t). This is called the cocktail-party problem. For the time being, we omit any time delays or other extra factors from our simplified mixing model. As an illustration, consider the waveforms in Fig. 1 and Fig. 2. These are, of course, not realistic speech signals, but suffice for this illustration. The original speech signals could look something like those in Fig. 1 and the mixed signals could look like those in Fig. 2. The problem is to recover the data in Fig. 1 using only the data in Fig. 2. Actually, if we knew the parameters a i j , we could solve the linear equation in (1) by classical methods. The point is, however, that if you don't know the a i j , the problem is considerably more difficult. One approach to solving this problem would be to use some information on the statistical properties of the signals s i (t) to estimate the a ii. Actually, and perhaps surprisingly, it turns out that it is enough to assume that s 1 (t) and s 2 (t), at each time instant t, are statistically independent. This is not an unrealistic assumption in many cases, 1},
author = {Aapo Hyv\"{a}rinen and Erkki Oja},
issue = {5},
journal = {Neural Networks},
keywords = {Independent component analysis,blind signal separation,factor analysis,projection pursuit,representation,source separation},
pages = {411-430},
title = {Independent Component Analysis: Algorithms and Applications},
volume = {13},
url = {https://www.cs.helsinki.fi/u/ahyvarin/papers/NN00new.pdf},
year = {2000},
}


@article{Carpenter:2006,
abstract = {Biologists can now prepare and image thousands of samples per day using automation, enabling chemical screens and functional genomics (for example, using RNA interference). Here we describe the first free, open-source system designed for flexible, high-throughput cell image analysis, CellProfiler. CellProfiler can address a variety of biological questions quantitatively, including standard assays (for example, cell count, size, per-cell protein levels) and complex morphological assays (for example, cell/organelle shape or subcellular patterns of DNA or protein staining).},
author = {Anne E Carpenter and Thouis R Jones and Michael R Lamprecht and Colin Clarke and In Kang and Ola Friman and others},
doi = {10.1186/gb-2006-7-10-r100},
issn = {14656906},
issue = {10},
journal = {Genome Biology},
keywords = {Animal Genetics and Genomics,Bioinformatics,Evolutionary Biology,Human Genetics,Microbial Genetics and Genomics,Plant Genetics \& Genomics},
month = {10},
pages = {R100},
publisher = {BioMed Central},
title = {CellProfiler: image analysis software for identifying and quantifying cell phenotypes},
volume = {7},
url = {http://genomebiology.biomedcentral.com/articles/10.1186/gb-2006-7-10-r100},
year = {2006},
}


@inbook{Kuse:2010,
author = {Manohar Kuse and Tanuj Sharma and Sudhir Gupta},
doi = {10.1007/978-3-642-17711-8_24},
pages = {235-243},
publisher = {Springer, Berlin, Heidelberg},
title = {A Classification Scheme for Lymphocyte Segmentation in H\&E Stained Histology Images},
url = {http://link.springer.com/10.1007/978-3-642-17711-8_24},
year = {2010},
}


@article{Dice:1945,
author = {Lee R. Dice},
doi = {10.2307/1932409},
issn = {00129658},
issue = {3},
journal = {Ecology},
month = {7},
pages = {297-302},
publisher = {John Wiley \& Sons, Ltd},
title = {Measures of the Amount of Ecologic Association Between Species},
volume = {26},
url = {http://doi.wiley.com/10.2307/1932409},
year = {1945},
}


@article{Huang:2018b,
abstract = {In this paper, we introduced a novel feature extraction approach, named exclusive autoencoder (XAE), which is a supervised version of autoencoder (AE), able to largely improve the performance of nucleus detection and classification on hematoxylin and eosin (H\&E) histopathological images. The proposed XAE can be used in any AE-based algorithm, as long as the data labels are also provided in the feature extraction phase. In the experiments, we evaluated the performance of an approach which is the combination of an XAE and a fully connected neural network (FCN) and compared with some AE-based methods. For a nucleus detection problem (considered as a nucleus/non-nucleus classification problem) on breast cancer H\&E images, the F-score of the proposed XAE+FCN approach achieved 96.64\% while the state-of-the-art was at 84.49\%. For nucleus classification on colorectal cancer H\&E images, with the annotations of four categories of epithelial, inflammatory, fibroblast and miscellaneous nuclei. The F-score of the proposed method reached 70.4\%. We also proposed a lymphocyte segmentation method. In the step of lymphocyte detection, we have compared with cutting-edge technology and gained improved performance from 90\% to 98.67\%. We also proposed an algorithm for lymphocyte segmentation based on nucleus detection and classification. The obtained Dice coefficient achieved 88.31\% while the cutting-edge approach was at 74\%.},
author = {Chao-Hui Huang and Daniel Racoceanu},
journal = {arXiv:1811.11243 [cs.CV]},
month = {11},
title = {eXclusive Autoencoder (XAE) for Nucleus Detection and Classification on Hematoxylin and Eosin (H\&E) Stained Histopathological Images},
url = {http://arxiv.org/abs/1811.11243},
year = {2018},
}


@article{Bankhead:2017,
abstract = {QuPath is new bioimage analysis software designed to meet the growing need for a user-friendly, extensible, open-source solution for digital pathology and whole slide image analysis. In addition to offering a comprehensive panel of tumor identification and high-throughput biomarker evaluation tools, QuPath provides researchers with powerful batch-processing and scripting functionality, and an extensible platform with which to develop and share new algorithms to analyze complex tissue images. Furthermore, QuPath’s flexible design makes it suitable for a wide range of additional image analysis applications across biomedical research.},
author = {Peter Bankhead and Maurice B. Loughrey and Jos\'{e} A. Fern\'{a}ndez and Yvonne Dombrowski and Darragh G. McArt and Philip D. Dunne and others},
doi = {10.1038/s41598-017-17204-5},
issn = {2045-2322},
issue = {1},
journal = {Scientific Reports},
keywords = {Biomarkers,Cancer imaging,Colon cancer,Image processing,Software},
month = {12},
pages = {16878},
publisher = {Nature Publishing Group},
title = {QuPath: Open source software for digital pathology image analysis},
volume = {7},
year = {2017},
}


@article{Tofighi:2018,
abstract = {Detection of cell nuclei in microscopic images is a challenging research topic, because of limitations in cellular image quality and diversity of nuclear morphology, i.e. varying nuclei shapes, sizes, and overlaps between multiple cell nuclei. This has been a topic of enduring interest with promising recent success shown by deep learning methods. These methods train for example convolutional neural networks (CNNs) with a training set of input images and known, labeled nuclei locations. Many of these methods are supplemented by spatial or morphological processing. We develop a new approach that we call Shape Priors with Convolutional Neural Networks (SP-CNN) to perform significantly enhanced nuclei detection. A set of canonical shapes is prepared with the help of a domain expert. Subsequently, we present a new network structure that can incorporate `expected behavior' of nucleus shapes via two components: \{\em learnable\} layers that perform the nucleus detection and a \{\em fixed\} processing part that guides the learning with prior information. Analytically, we formulate a new regularization term that is targeted at penalizing false positives while simultaneously encouraging detection inside cell nucleus boundary. Experimental results on a challenging dataset reveal that SP-CNN is competitive with or outperforms several state-of-the-art methods.},
author = {Mohammad Tofighi and Tiantong Guo and Jairam K. P. Vanamala and Vishal Monga},
month = {6},
title = {Deep Networks with Shape Priors for Nucleus Detection},
url = {http://arxiv.org/abs/1807.03135},
year = {2018},
}


@article{Kingma:2014,
author = {Diederik P. Kingma and Jimmy Ba},
month = {12},
title = {Adam: A Method for Stochastic Optimization},
url = {https://arxiv.org/abs/1412.6980},
year = {2014},
}


@article{Hu:2016,
author = {Zhirui Hu},
title = {and TCGA data},
year = {2016},
}


@article{Qaiser:2018,
abstract = {Aims: Evaluating expression of the human epidermal growth factor receptor 2 (HER2) by visual examination of immunohistochemistry (IHC) on invasive breast cancer (BCa) is a key part of the diagnostic assessment of BCa due to its recognized importance as a predictive and prognostic marker in clinical practice. However, visual scoring of HER2 is subjective, and consequently prone to interobserver variability. Given the prognostic and therapeutic implications of HER2 scoring, a more objective method is required. In this paper, we report on a recent automated HER2 scoring contest, held in conjunction with the annual PathSoc meeting held in Nottingham in June 2016, aimed at systematically comparing and advancing the state-of-the-art artificial intelligence (AI)-based automated methods for HER2 scoring. Methods and results: The contest data set comprised digitized whole slide images (WSI) of sections from 86 cases of invasive breast carcinoma stained with both haematoxylin and eosin (H\&E) and IHC for HER2. The contesting algorithms predicted scores of the IHC slides automatically for an unseen subset of the data set and the predicted scores were compared with the ‘ground truth’ (a consensus score from at least two experts). We also report on a simple ‘Man versus Machine’ contest for the scoring of HER2 and show that the automated methods could beat the pathology experts on this contest data set. Conclusions: This paper presents a benchmark for comparing the performance of automated algorithms for scoring of HER2. It also demonstrates the enormous potential of automated algorithms in assisting the pathologist with objective IHC scoring.},
author = {Talha Qaiser and Abhik Mukherjee and Chaitanya Reddy PB and Sai D. Munugoti and Vamsi Tallam and Tomi Pitk\"{a}aho and others},
doi = {10.1111/his.13333},
issn = {13652559},
issue = {2},
journal = {Histopathology},
keywords = {automated HER2 scoring,biomarker quantification,breast cancer,digital pathology,quantitative immunohistochemistry},
month = {1},
pages = {227-238},
publisher = {Blackwell Publishing Ltd},
title = {HER2 challenge contest: a detailed assessment of automated HER2 scoring algorithms in whole slide images of breast cancer tissues},
volume = {72},
year = {2018},
}


@article{Gutman:2017,
abstract = {Tissue-based cancer studies can generate large amounts of histology data in the form of glass slides. These slides contain important diagnostic, prognostic, and biological information and can be digitized into expansive and high-resolution whole-slide images using slide-scanning devices. Effectively utilizing digital pathology data in cancer research requires the ability to manage, visualize, share, and perform quantitative analysis on these large amounts of image data, tasks that are often complex and difficult for investigators with the current state of commercial digital pathology software. In this article, we describe the Digital Slide Archive (DSA), an open-source web-based platform for digital pathology. DSA allows investigators to manage large collections of histologic images and integrate them with clinical and genomic metadata. The open-source model enables DSA to be extended to provide additional capabilities.},
author = {David A. Gutman and Mohammed Khalilia and Sanghoon Lee and Michael Nalisnik and Zach Mullen and Jonathan Beezley and others},
doi = {10.1158/0008-5472.CAN-17-0629},
issn = {15387445},
issue = {21},
journal = {Cancer Research},
month = {11},
pages = {e75-e78},
publisher = {American Association for Cancer Research Inc.},
title = {The digital slide archive: A software platform for management, integration, and analysis of histology for cancer research},
volume = {77},
year = {2017},
}


@article{Schapiro:2017,
abstract = {Single-cell, spatially resolved omics analysis of tissues is poised to transform biomedical research and clinical practice. We have developed an open-source, computational histology topography cytometry analysis toolbox (histoCAT) to enable interactive, quantitative, and comprehensive exploration of individual cell phenotypes, cell-cell interactions, microenvironments, and morphological structures within intact tissues. We highlight the unique abilities of histoCAT through analysis of highly multiplexed mass cytometry images of human breast cancer tissues.},
author = {Denis Schapiro and Hartland W. Jackson and Swetha Raghuraman and Jana R. Fischer and Vito R.T. Zanotelli and Daniel Schulz and others},
doi = {10.1038/nmeth.4391},
issn = {15487105},
issue = {9},
journal = {Nature Methods},
keywords = {Imaging,Software},
month = {8},
pages = {873-876},
publisher = {Nature Publishing Group},
title = {HistoCAT: Analysis of cell phenotypes and interactions in multiplex image cytometry data},
volume = {14},
year = {2017},
}


@article{Hafemeister:2019,
abstract = {Single-cell RNA-seq (scRNA-seq) data exhibits significant cell-to-cell variation due to technical factors, including the number of molecules detected in each cell, which can confound biological heterogeneity with technical effects. To address this, we present a modeling framework for the normalization and variance stabilization of molecular count data from scRNA-seq experiments. We propose that the Pearson residuals from "regularized negative binomial regression," where cellular sequencing depth is utilized as a covariate in a generalized linear model, successfully remove the influence of technical characteristics from downstream analyses while preserving biological heterogeneity. Importantly, we show that an unconstrained negative binomial model may overfit scRNA-seq data, and overcome this by pooling information across genes with similar abundances to obtain stable parameter estimates. Our procedure omits the need for heuristic steps including pseudocount addition or log-transformation and improves common downstream analytical tasks such as variable gene selection, dimensional reduction, and differential expression. Our approach can be applied to any UMI-based scRNA-seq dataset and is freely available as part of the R package sctransform, with a direct interface to our single-cell toolkit Seurat.},
author = {Christoph Hafemeister and Rahul Satija},
doi = {10.1186/S13059-019-1874-1/FIGURES/6},
issn = {1474760X},
issue = {1},
journal = {Genome Biology},
keywords = {Normalization,Single-cell RNA-seq},
month = {12},
pages = {1-15},
pmid = {31870423},
publisher = {BioMed Central Ltd.},
title = {Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression},
volume = {20},
url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1},
year = {2019},
}


@article{Bergenstrahle:2021,
abstract = {Current methods for spatial transcriptomics are limited by low spatial resolution. Here we introduce a method that integrates spatial gene expression data with histological image data from the same tissue section to infer higher-resolution expression maps. Using a deep generative model, our method characterizes the transcriptome of micrometer-scale anatomical features and can predict spatial gene expression from histology images alone. The low resolution of spatial transcriptomics is substantially improved by including histology images.},
author = {Ludvig Bergenstr{\aa}hle and Bryan He and Joseph Bergenstr{\aa}hle and Xes\'{u}s Abalo and Reza Mirzazadeh and Kim Thrane and others},
doi = {10.1038/s41587-021-01075-3},
issn = {1546-1696},
journal = {Nature Biotechnology 2021},
keywords = {Data integration,Gene expression,Machine learning},
month = {11},
pages = {1-4},
publisher = {Nature Publishing Group},
title = {Super-resolved spatial transcriptomics by deep data fusion},
url = {https://www.nature.com/articles/s41587-021-01075-3},
year = {2021},
}


@article{Dietterich:1997,
abstract = {The multiple instance problem arises in tasks where the training examples are ambiguous: a single example object may have many alternative feature vectors (instances) that describe it, and yet only one of those feature vectors may be responsible for the observed classification of the object. This paper describes and compares three kinds of algorithms that learn axis-parallel rectangles to solve the multiple instance problem. Algorithms that ignore the multiple instance problem perform very poorly. An algorithm that directly confronts the multiple instance problem (by attempting to identify which feature vectors are responsible for the observed classifications) performs best, giving 89\% correct predictions on a musk odor prediction task. The paper also illustrates the use of artificial data to debug and compare these algorithms.},
author = {Thomas G. Dietterich and Richard H. Lathrop and Tom\'{a}s Lozano-P\'{e}rez},
doi = {10.1016/S0004-3702(96)00034-3},
issn = {0004-3702},
issue = {1-2},
journal = {Artificial Intelligence},
keywords = {Drug design,Machine learning,Structure-activity relationships},
month = {1},
pages = {31-71},
publisher = {Elsevier},
title = {Solving the multiple instance problem with axis-parallel rectangles},
volume = {89},
year = {1997},
}


@article{Kraus:2016,
abstract = {Motivation: High-content screening (HCS) technologies have enabled large scale imaging experiments for studying cell biology and for drug screening. These systems produce hundreds of thousands of microscopy images per day and their utility depends on automated image analysis. Recently, deep learning approaches that learn feature representations directly from pixel intensity values have dominated object recognition challenges. These tasks typically have a single centered object per image and existing models are not directly applicable to microscopy datasets. Here we develop an approach that combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. Results: We introduce a new neural network architecture that uses MIL to simultaneously classify and segment microscopy images with populations of cells. We base our approach on the similarity between the aggregation function used in MIL and pooling layers used in CNNs. To facilitate aggregating across large numbers of instances in CNN feature maps we present the Noisy-AND pooling function, a new MIL operator that is robust to outliers. Combining CNNs with MIL enables training CNNs using whole microscopy images with image level labels. We show that training end-to-end MIL CNNs outperforms several previous methods on both mammalian and yeast datasets without requiring any segmentation steps.},
author = {Oren Z. Kraus and Jimmy Lei Ba and Brendan J. Frey},
doi = {10.1093/BIOINFORMATICS/BTW252},
issn = {1367-4811},
issue = {12},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Brendan J Frey,Computer,Computer-Assisted*,Humans,Image Interpretation,Jimmy Lei Ba,MEDLINE,Machine Learning*,Microscopy*,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neural Networks,Oren Z Kraus,PMC4908336,PubMed Abstract,Yeasts / cytology,doi:10.1093/bioinformatics/btw252,pmid:27307644},
month = {6},
pages = {i52-i59},
pmid = {27307644},
publisher = {Bioinformatics},
title = {Classifying and segmenting microscopy images with deep multiple instance learning},
volume = {32},
url = {https://pubmed.ncbi.nlm.nih.gov/27307644/},
year = {2016},
}


@article{Walker:2021,
abstract = {In recent years, the task of video prediction-forecasting future video given 
past video frames-has attracted attention in the research community. In this 
paper we propose a novel approach to this problem with Vector Quantized 
Variational AutoEncoders (VQ-VAE). With VQ-VAE we compress high-resolution 
videos into a hierarchical set of multi-scale discrete latent variables. 
Compared to pixels, this compressed latent space has dramatically reduced 
dimensionality, allowing us to apply scalable autoregressive generative models 
to predict video. In contrast to previous work that has largely emphasized 
highly constrained datasets, we focus on very diverse, large-scale datasets 
such as Kinetics-600. We predict video at a higher resolution on unconstrained 
videos, 256x256, than any other previous method to our knowledge. We further 
validate our approach against prior work via a crowdsourced human evaluation.},
author = {Jacob Walker and Ali Razavi and A\"{a}ron van den Oord},
month = {3},
title = {Predicting Video with VQVAE},
url = {https://arxiv.org/abs/2103.01950v1},
year = {2021},
}


@article{Stahl:2016,
abstract = {Analysis of the pattern of proteins or messenger RNAs (mRNAs) in histological tissue sections is a cornerstone in biomedical research and diagnostics.This typically involves the visualization of a few proteins or expressed genes at a time. We have devised a strategy, which we call "spatial transcriptomics," that allows visualization and quantitative analysis of the transcriptome with spatial resolution in individual tissue sections. By positioning histological sections on arrayed reverse transcription primers with unique positional barcodes, we demonstrate high-quality RNA-sequencing data with maintained two-dimensional positional information from the mouse brain and human breast cancer. Spatial transcriptomics provides quantitative gene expression data and visualization of the distribution of mRNAs within tissue sections and enables novel types of bioinformatics analyses, valuable in research and diagnostics.},
author = {Patrik L. St{\aa}hl and Fredrik Salm\'{e}n and Sanja Vickovic and Anna Lundmark and Jos\'{e} Fern\'{a}ndez Navarro and Jens Magnusson and others},
doi = {10.1126/SCIENCE.AAF2403},
issn = {10959203},
issue = {6294},
journal = {Science},
month = {7},
pages = {78-82},
pmid = {27365449},
publisher = {American Association for the Advancement of Science},
title = {Visualization and analysis of gene expression in tissue sections by spatial transcriptomics},
volume = {353},
year = {2016},
}


@article{Rumelhart:2013,
author = {D. E. Rumelhart and G. E. Hinton and R. J. Williams},
doi = {10.1016/B978-1-4832-1446-7.50035-2},
isbn = {1558600132},
journal = {Readings in Cognitive Science: A Perspective from Psychology and Artificial Intelligence},
month = {10},
pages = {399-421},
publisher = {Elsevier Inc.},
title = {Learning Internal Representations by Error Propagation},
year = {2013},
}


@article{Shah:2016,
abstract = {Identifying the spatial organization of tissues at cellular resolution from single-cell gene expression profiles is essential to understanding biological systems. Using an in situ 3D multiplexed imaging method, seqFISH, we identify unique transcriptional states by quantifying and clustering up to 249 genes in 16,958 cells to examine whether the hippocampus is organized into transcriptionally distinct subregions. We identified distinct layers in the dentate gyrus corresponding to the granule cell layer and the subgranular zone and, contrary to previous reports, discovered that distinct subregions within the CA1 and CA3 are composed of unique combinations of cells in different transcriptional states. In addition, we found that the dorsal CA1 is relatively homogeneous at the single cell level, while ventral CA1 is highly heterogeneous. These structures and patterns are observed using different mice and different sets of genes. Together, these results demonstrate the power of seqFISH in transcriptional profiling of complex tissues.},
author = {Sheel Shah and Eric Lubeck and Wen Zhou and Long Cai},
doi = {10.1016/J.NEURON.2016.10.001},
issn = {0896-6273},
issue = {2},
journal = {Neuron},
month = {10},
pages = {342-357},
pmid = {27764670},
publisher = {Cell Press},
title = {In Situ Transcription Profiling of Single Cells Reveals Spatial Organization of Cells in the Mouse Hippocampus},
volume = {92},
year = {2016},
}


@article{Rodriques:2019,
abstract = {Spatial positions of cells in tissues strongly influence function, yet a high-throughput, genome-wide readout of gene expression with cellular resolution is lacking.We developed Slide-seq, a method for transferring RNA from tissue sections onto a surface covered in DNA-barcoded beads with known positions, allowing the locations of the RNA to be inferred by sequencing. Using Slide-seq, we localized cell types identified by single-cell RNA sequencing datasets within the cerebellum and hippocampus, characterized spatial gene expression patterns in the Purkinje layer of mouse cerebellum, and defined the temporal evolution of cell type-specific responses in a mouse model of traumatic brain injury. These studies highlight how Slide-seq provides a scalable method for obtaining spatially resolved gene expression data at resolutions comparable to the sizes of individual cells.},
author = {Samuel G. Rodriques and Robert R. Stickels and Aleksandrina Goeva and Carly A. Martin and Evan Murray and Charles R. Vanderburg and others},
doi = {10.1126/SCIENCE.AAW1219/SUPPL_FILE/AAW1219S1.MOV},
issn = {10959203},
issue = {6434},
journal = {Science},
month = {3},
pages = {1463-1467},
pmid = {30923225},
publisher = {American Association for the Advancement of Science},
title = {Slide-seq: A scalable technology for measuring genome-wide expression at high spatial resolution},
volume = {363},
url = {https://www-science-org.eu1.proxy.openathens.net/doi/abs/10.1126/science.aaw1219},
year = {2019},
}


@article{Vickovic:2019,
abstract = {Spatial and molecular characteristics determine tissue function, yet high-resolution methods to capture both concurrently are lacking. Here, we developed high-definition spatial transcriptomics, which captures RNA from histological tissue sections on a dense, spatially barcoded bead array. Each experiment recovers several hundred thousand transcript-coupled spatial barcodes at 2-$\mu$m resolution, as demonstrated in mouse brain and primary breast cancer. This opens the way to high-resolution spatial analysis of cells and tissues. A dense, spatially barcoded bead array captures RNA from histological tissue sections for spatially resolved gene expression analysis.},
author = {Sanja Vickovic and G\"{o}kcen Eraslan and Fredrik Salm\'{e}n and Johanna Klughammer and Linnea Stenbeck and Denis Schapiro and others},
doi = {10.1038/S41592-019-0548-Y},
issn = {1548-7105},
issue = {10},
journal = {Nature Methods},
keywords = {Gene expression,RNA sequencing},
month = {9},
pages = {987-990},
pmid = {31501547},
publisher = {Nature Publishing Group},
title = {High-definition spatial transcriptomics for in situ tissue profiling},
volume = {16},
url = {https://www-nature-com.eu1.proxy.openathens.net/articles/s41592-019-0548-y},
year = {2019},
}


@article{Moncada:2020,
abstract = {Single-cell RNA sequencing (scRNA-seq) enables the systematic identification of cell populations in a tissue, but characterizing their spatial organization remains challenging. We combine a microarray-based spatial transcriptomics method that reveals spatial patterns of gene expression using an array of spots, each capturing the transcriptomes of multiple adjacent cells, with scRNA-Seq generated from the same sample. To annotate the precise cellular composition of distinct tissue regions, we introduce a method for multimodal intersection analysis. Applying multimodal intersection analysis to primary pancreatic tumors, we find that subpopulations of ductal cells, macrophages, dendritic cells and cancer cells have spatially restricted enrichments, as well as distinct coenrichments with other cell types. Furthermore, we identify colocalization of inflammatory fibroblasts and cancer cells expressing a stress-response gene module. Our approach for mapping the architecture of scRNA-seq-defined subpopulations can be applied to reveal the interactions inherent to complex tissues. Combining single-cell RNA-seq data and microarray-based spatial transcriptomics maps the location of different cell types and cell states in pancreatic tumors.},
author = {Reuben Moncada and Dalia Barkley and Florian Wagner and Marta Chiodin and Joseph C. Devlin and Maayan Baron and others},
doi = {10.1038/S41587-019-0392-8},
issn = {1546-1696},
issue = {3},
journal = {Nature Biotechnology 2020 38:3},
keywords = {Cancer,Data integration,Gene expression analysis},
month = {1},
pages = {333-342},
pmid = {31932730},
publisher = {Nature Publishing Group},
title = {Integrating microarray-based spatial transcriptomics and single-cell RNA-seq reveals tissue architecture in pancreatic ductal adenocarcinomas},
volume = {38},
url = {https://www-nature-com.eu1.proxy.openathens.net/articles/s41587-019-0392-8},
year = {2020},
}


@article{Berglund:2018,
abstract = {Intra-tumor heterogeneity is one of the biggest challenges in cancer treatment today. Here we investigate tissue-wide gene expression heterogeneity throughout a multifocal prostate cancer using the spatial transcriptomics (ST) technology. Utilizing a novel approach for deconvolution, we analyze the transcriptomes of nearly 6750 tissue regions and extract distinct expression profiles for the different tissue components, such as stroma, normal and PIN glands, immune cells and cancer. We distinguish healthy and diseased areas and thereby provide insight into gene expression changes during the progression of prostate cancer. Compared to pathologist annotations, we delineate the extent of cancer foci more accurately, interestingly without link to histological changes. We identify gene expression gradients in stroma adjacent to tumor regions that allow for re-stratification of the tumor microenvironment. The establishment of these profiles is the first step towards an unbiased view of prostate cancer and can serve as a dictionary for future studies. Heterogeneity within tumors presents a challenge to cancer treatment. Here, the authors investigate transcriptional heterogeneity in prostate cancer, examining expression profiles of different tissue components and highlighting expression gradients in the tumor microenvironment.},
author = {Emelie Berglund and Jonas Maaskola and Niklas Schultz and Stefanie Friedrich and Maja Marklund and Joseph Bergenstr{\aa}hle and others},
doi = {10.1038/S41467-018-04724-5},
issn = {2041-1723},
issue = {1},
journal = {Nature Communications 2018 9:1},
keywords = {Computational models,Probabilistic data networks,RNA sequencing,Transcription,Tumour heterogeneity},
month = {6},
pages = {1-13},
pmid = {29925878},
publisher = {Nature Publishing Group},
title = {Spatial maps of prostate cancer transcriptomes reveal an unexplored landscape of heterogeneity},
volume = {9},
url = {https://www-nature-com.eu1.proxy.openathens.net/articles/s41467-018-04724-5},
year = {2018},
}


@inproceedings{Oord:2017,
abstract = {Learning useful representations without supervision remains a key challenge 
in machine learning. In this paper, we propose a simple yet powerful generative 
model that learns such discrete representations. Our model, the Vector 
Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: 
the encoder network outputs discrete, rather than continuous, codes; and the 
prior is learnt rather than static. In order to learn a discrete latent 
representation, we incorporate ideas from vector quantisation (VQ). Using the 
VQ method allows the model to circumvent issues of "posterior collapse" -- 
where the latents are ignored when they are paired with a powerful 
autoregressive decoder -- typically observed in the VAE framework. Pairing 
these representations with an autoregressive prior, the model can generate high 
quality images, videos, and speech as well as doing high quality speaker 
conversion and unsupervised learning of phonemes, providing further evidence of 
the utility of the learnt representations.},
author = {Aaron Van Den Oord and Oriol Vinyals and Koray kavukcuoglu},
editor = {I Guyon and U V Luxburg and S Bengio and H Wallach and R Fergus and S Vishwanathan and R Garnett},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {11},
pages = {6307-6316},
publisher = {Curran Associates, Inc.},
title = {Neural Discrete Representation Learning},
volume = {30},
url = {https://proceedings.neurips.cc/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf https://arxiv.org/abs/1711.00937v2},
year = {2017},
}


@article{Schmidt:2018,
abstract = {Automatic detection and segmentation of cells and nuclei in microscopy images 
is important for many biological applications. Recent successful learning-based 
approaches include per-pixel cell segmentation with subsequent pixel grouping, 
or localization of bounding boxes with subsequent shape refinement. In 
situations of crowded cells, these can be prone to segmentation errors, such as 
falsely merging bordering cells or suppressing valid cell instances due to the 
poor approximation with bounding boxes. To overcome these issues, we propose to 
localize cell nuclei via star-convex polygons, which are a much better shape 
representation as compared to bounding boxes and thus do not need shape 
refinement. To that end, we train a convolutional neural network that predicts 
for every pixel a polygon for the cell instance at that position. We 
demonstrate the merits of our approach on two synthetic datasets and one 
challenging dataset of diverse fluorescence microscopy images.},
author = {Uwe Schmidt and Martin Weigert and Coleman Broaddus and Gene Myers},
doi = {10.1007/978-3-030-00934-2_30},
isbn = {9783030009335},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
month = {6},
pages = {265-273},
publisher = {Springer Verlag},
title = {Cell Detection with Star-convex Polygons},
volume = {11071 LNCS},
url = {https://arxiv.org/abs/1806.03535v2},
year = {2018},
}


@article{Elomaa:2022,
abstract = {Although high T cell density is a strong favourable prognostic factor in colorectal cancer, the significance of the spatial distribution of T cells is incompletely understood. We aimed to evaluate the prognostic significance of tumour cell-T cell co-localisation and T cell densities. We analysed CD3 and CD8 immunohistochemistry in a study cohort of 983 colorectal cancer patients and a validation cohort (N = 246). Individual immune and tumour cells were identified to calculate T cell densities (to derive T cell density score) and G-cross function values, estimating the likelihood of tumour cells being co-located with T cells within 20 µm radius (to derive T cell proximity score). High T cell proximity score associated with longer cancer-specific survival in both the study cohort [adjusted HR for high (vs. low) 0.33, 95\% CI 0.20-0.52, Ptrend \&lt; 0.0001] and the validation cohort [adjusted HR for high (vs. low) 0.15, 95\% CI 0.05-0.45, Ptrend \&lt; 0.0001] and its prognostic value was independent of T cell density score. The spatial point pattern analysis of tumour cell-T cell co-localisation could provide detailed information on colorectal cancer prognosis, supporting the value of spatial measurement of T cell infiltrates as a novel, robust tumour-immune biomarker.},
author = {Hanna Elomaa and Maarit Ahtiainen and Sara A. V\"{a}yrynen and Shuji Ogino and Jonathan A. Nowak and Marjukka Friman and others},
doi = {10.1038/s41416-022-01822-6},
issn = {1532-1827},
journal = {British Journal of Cancer 2022},
keywords = {Cancer microenvironment,Colorectal cancer,Tumour immunology},
month = {4},
pages = {1-10},
publisher = {Nature Publishing Group},
title = {Prognostic significance of spatial and density analysis of T lymphocytes in colorectal cancer},
url = {https://www.nature.com/articles/s41416-022-01822-6},
year = {2022},
}


@article{Schmidt:2022,
author = {Gilda Schmidt and Margit Maria Guhl and Erich-Franz Solomayer and Gudrun Wagenpfeil and Mohammed Eid Hammadeh and Ingolf Juhasz-Boess and others},
doi = {10.1007/S00404-022-06529-W},
issn = {1432-0711},
journal = {Archives of gynecology and obstetrics},
keywords = {Gilda Schmidt,MEDLINE,Margit Maria Guhl,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PubMed Abstract,Rainer Maria Bohle,doi:10.1007/s00404-022-06529-w,pmid:35377046},
month = {4},
pmid = {35377046},
publisher = {Arch Gynecol Obstet},
title = {Immunohistochemical assessment of PD-L1 expression using three different monoclonal antibodies in triple negative breast cancer patients},
url = {https://pubmed.ncbi.nlm.nih.gov/35377046/},
year = {2022},
}


@article{Barisoni:2020,
abstract = {The emergence of digital pathology — an image-based environment for the acquisition, management and interpretation of pathology information supported by computational techniques for data extraction and analysis — is changing the pathology ecosystem. In particular, by virtue of our new-found ability to generate and curate digital libraries, the field of machine vision can now be effectively applied to histopathological subject matter by individuals who do not have deep expertise in machine vision techniques. Although these novel approaches have already advanced the detection, classification, and prognostication of diseases in the fields of radiology and oncology, renal pathology is just entering the digital era, with the establishment of consortia and digital pathology repositories for the collection, analysis and integration of pathology data with other domains. The development of machine-learning approaches for the extraction of information from image data, allows for tissue interrogation in a way that was not previously possible. The application of these novel tools are placing pathology centre stage in the process of defining new, integrated, biologically and clinically homogeneous disease categories, to identify patients at risk of progression, and shifting current paradigms for the treatment and prevention of kidney diseases. Developments in digital pathology and computational image analysis have the potential to identify new disease mechanisms, improve disease classification and prognostication, and ultimately aid the identification of targeted therapies. In this Review, the authors provide an outline of the digital ecosystem in nephropathology and describe potential applications and challenges associated with the emerging armamentarium of technologies for image analysis.},
author = {Laura Barisoni and Kyle J. Lafata and Stephen M. Hewitt and Anant Madabhushi and Ulysses G.J. Balis},
doi = {10.1038/s41581-020-0321-6},
issn = {1759-507X},
issue = {11},
journal = {Nature Reviews Nephrology 2020 16:11},
keywords = {Kidney diseases,Systems biology},
month = {8},
pages = {669-685},
pmid = {32848206},
publisher = {Nature Publishing Group},
title = {Digital pathology and computational image analysis in nephropathology},
volume = {16},
url = {https://www.nature.com/articles/s41581-020-0321-6},
year = {2020},
}


@article{Kumar:2020,
abstract = {Whole slide imaging (WSI), ever since its first introduction about two decades ago, has been validated for a number of applications in the field of pathology. The recent approval of US FDA to a WSI system for use in primary surgical pathology diagnosis has opened avenues for wider acceptance and application of this technology in routine practice. The ongoing technological advances in digital scanners, image visualization methods, and the integration of artificial intelligence-derived algorithms with these systems provide opportunities of its newer applications. Its benefits are innumerable such as ease of access through internet, avoidance of physical storage space, and no risk of deterioration of staining quality or breakage of slides to name a few. Various barriers such as the high cost, technical glitches, and professional hesitation to adopt a new technology have hindered its use in pathology. This review article summarizes the technical aspects of WSI, its applications in diagnostic pathology, training, and research along with future perspectives. It highlights the benefits, limitations, and challenges delaying the use of this technology in routine practice. The review is targeted at students, residents, and budding pathologists to better acquaint them with the key aspects of state-of-the-art technology and enable them to implement WSI judiciously.},
author = {Neeta Kumar and Ruchika Gupta and Sanjay Gupta},
doi = {10.1007/S10278-020-00351-Z},
issn = {1618727X},
issue = {4},
journal = {Journal of Digital Imaging},
keywords = {Automated image analysis,Cytopathology,Diagnosis,Education,Regulation,Telepathology,Validation,Whole slide imaging},
month = {8},
pages = {1034-1040},
pmid = {32468487},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {Whole Slide Imaging (WSI) in Pathology: Current Perspectives and Future Directions},
volume = {33},
year = {2020},
}


@article{Rodriguez:2021,
abstract = {Tumor-associated tertiary lymphoid structures (TA-TLS) are associated with enhanced patient survival and responsiveness to cancer therapies, but the mechanisms underlying their development are unknown. We show here that TA-TLS development in murine melanoma is orchestrated by cancer-associated fibroblasts (CAF) with characteristics of lymphoid tissue organizer cells that are induced by tumor necrosis factor receptor signaling. CAF organization into reticular networks is mediated by CD8 T cells, while CAF accumulation and TA-TLS expansion depend on CXCL13-mediated recruitment of B cells expressing lymphotoxin-$\alpha$1$\beta$2. Some of these elements are also overrepresented in human TA-TLS. Additionally, we demonstrate that immunotherapy induces more and larger TA-TLS that are more often organized with discrete T and B cell zones, and that TA-TLS presence, number, and size are correlated with reduced tumor size and overall response to checkpoint immunotherapy. This work provides a platform for manipulating TA-TLS development as a cancer immunotherapy strategy.},
author = {Anthony B. Rodriguez and J. David Peske and Amber N. Woods and Katie M. Leick and Ileana S. Mauldin and Max O. Meneveau and others},
doi = {10.1016/J.CELREP.2021.109422},
issn = {2211-1247},
issue = {3},
journal = {Cell reports},
keywords = {Animals,Anthony B Rodriguez,B-Lymphocytes / immunology,CD8-Positive T-Lymphocytes / immunology,Cancer-Associated Fibroblasts / pathology*,Cell Differentiation,Cell Proliferation,Humans,Immunotherapy,Inbred C57BL,J David Peske,Lymphocyte Activation / immunology,Lymphotoxin beta Receptor / metabolism,MEDLINE,Membrane Glycoproteins / metabolism,Mice,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neoplasms / immunology*,Neoplasms / pathology*,Neoplasms / therapy,Non-U.S. Gov't,P.H.S.,PMC8362934,Peritoneum / pathology,PubMed Abstract,Receptors,Research Support,Signal Transduction,Tertiary Lymphoid Structures / immunology*,Tumor Necrosis Factor / metabolism,U.S. Gov't,Victor H Engelhard,doi:10.1016/j.celrep.2021.109422,pmid:34289373},
month = {7},
pmid = {34289373},
publisher = {Cell Rep},
title = {Immune mechanisms orchestrate tertiary lymphoid structures in tumors via cancer-associated fibroblasts},
volume = {36},
url = {https://pubmed.ncbi.nlm.nih.gov/34289373/},
year = {2021},
}


@article{Peng:2022,
abstract = {BACKGROUND The tumor-promoting role of tumor microenvironment (TME) in colorectal cancer has been widely investigated in cancer biology. Cancer-associated fibroblasts (CAFs), as the main stromal component in TME, play an important role in promoting tumor progression and metastasis. Hence, we explored the crosstalk between CAFs and microenvironment in the pathogenesis of colorectal cancer in order to provide basis for precision therapy. METHODS We integrated spatial transcriptomics (ST) and bulk-RNA sequencing datasets to explore the functions of CAFs in the microenvironment of CRC. In detail, single sample gene set enrichment analysis (ssGSEA), gene set variation analysis (GSVA), pseudotime analysis and cell proportion analysis were utilized to identify the cell types and functions of each cell cluster. Immunofluorescence and immunohistochemistry were applied to confirm the results based on bioinformatics analysis. RESULTS We profiled the tumor heterogeneity landscape and identified two distinct types of CAFs, which myo-cancer-associated fibroblasts (mCAFs) is associated with myofibroblast-like cells and inflammatory-cancer-associated fibroblasts (iCAFs) is related to immune inflammation. When we carried out functional analysis of two types of CAFs, we uncovered an extensive crosstalk between iCAFs and stromal components in TME to promote tumor progression and metastasis. Noticeable, some anti-tumor immune cells such as NK cells, monocytes were significantly reduced in iCAFs-enriched cluster. Then, ssGSEA analysis results showed that iCAFs were related to EMT, lipid metabolism and bile acid metabolism etc. Besides, when we explored the relationship of chemotherapy and microenvironment, we detected that iCAFs influenced immunosuppressive cells and lipid metabolism reprogramming in patient who underwent chemotherapy. Additionally, we identified the clinical role of iCAFs through a public database and confirmed it were related to poor prognosis. CONCLUSIONS In summary, we identified two types of CAFs using integrated data and explored their functional significance in TME. This in-depth understanding of CAFs in microenvironment may help us to elucidate its cancer-promoting functions and offer hints for therapeutic studies.},
author = {Zhiwei Peng and Manping Ye and Huiming Ding and Zhenyou Feng and Kongwang Hu},
doi = {10.1186/S12967-022-03510-8},
issn = {1479-5876},
issue = {1},
journal = {Journal of translational medicine},
keywords = {Cancer-Associated Fibroblasts* / metabolism,Cancer-Associated Fibroblasts* / pathology,Colorectal Neoplasms* / pathology,Humans,Kongwang Hu,MEDLINE,Manping Ye,Monocytes / metabolism,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,PMC9258101,PubMed Abstract,Transcriptome / genetics,Tumor Microenvironment / genetics,Zhiwei Peng,doi:10.1186/s12967-022-03510-8,pmid:35794563},
month = {7},
pages = {302},
pmid = {35794563},
publisher = {J Transl Med},
title = {Spatial transcriptomics atlas reveals the crosstalk between cancer-associated fibroblasts and tumor microenvironment components in colorectal cancer},
volume = {20},
url = {https://pubmed.ncbi.nlm.nih.gov/35794563/},
year = {2022},
}


@article{Wu:2022,
abstract = {Multiplexed immunofluorescence imaging enables high-dimensional molecular profiling at subcellular resolution. However, learning disease-relevant cellular environments from these rich imaging data is an open challenge. We developed SPAtial CEllular Graphical Modeling (SPACE-GM), a geometric deep learning framework that flexibly models tumor microenvironments (TMEs) as cellular graphs. We applied SPACE-GM to 658 head-and-neck and colorectal human cancer samples assayed with 40-plex immunofluorescence imaging to identify spatial motifs associated with cancer recurrence and patient survival after immunotherapy. SPACE-GM is substantially more accurate in predicting patient outcomes than previous approaches for modeling spatial data using neighborhood cell-type compositions. Computational interpretation of the disease-relevant microenvironments identified by SPACE-GM generates insights into the effect of spatial dispersion of tumor cells and granulocytes on patient prognosis. 
 
### Competing Interest Statement 
 
Several authors are affiliated with Enable Medicine as employees (A.E.T., H.J.K., H.B.D, R.P., and A.T.M.), consultants (Z.W., E.W.), or scientific advisor (J.Z.).},
author = {Zhenqin Wu and Alexandro E Trevino and Eric Wu and Kyle Swanson and Honesty J Kim and H Blaize D'angio and others},
doi = {10.1101/2022.05.12.491707},
journal = {bioRxiv},
month = {5},
pages = {2022.05.12.491707},
publisher = {Cold Spring Harbor Laboratory},
title = {SPACE-GM: geometric deep learning of disease-associated microenvironments from multiplex spatial protein profiles},
url = {https://www.biorxiv.org/content/10.1101/2022.05.12.491707v1 https://www.biorxiv.org/content/10.1101/2022.05.12.491707v1.abstract},
year = {2022},
}


@article{Ternes:2022,
abstract = {Image-based cell phenotyping relies on quantitative measurements as encoded representations of cells; however, defining suitable representations that capture complex imaging features is challenged by the lack of robust methods to segment cells, identify subcellular compartments, and extract relevant features. Variational autoencoder (VAE) approaches produce encouraging results by mapping an image to a representative descriptor, and outperform classical hand-crafted features for morphology, intensity, and texture at differentiating data. Although VAEs show promising results for capturing morphological and organizational features in tissue, single cell image analyses based on VAEs often fail to identify biologically informative features due to uninformative technical variation. Here we propose a multi-encoder VAE (ME-VAE) in single cell image analysis using transformed images as a self-supervised signal to extract transform-invariant biologically meaningful features, including emergent features not obvious from prior knowledge. We show that the proposed architecture improves analysis by making distinct cell populations more separable compared to traditional and recent extensions of VAE architectures and intensity measurements by enhancing phenotypic differences between cells and by improving correlations to other analytic modalities. Better feature extraction and image analysis methods enabled by the ME-VAE will advance our understanding of complex cell biology and enable discoveries previously hidden behind image complexity ultimately improving medical outcomes and drug discovery. The Multi-Encoder Variational AutoEncoder (ME-VAE) is a computational model that can control for multiple transformational features in single-cell imaging data, enabling researchers to extract meaningful single-cell information and better separate heterogeneous cell types.},
author = {Luke Ternes and Mark Dane and Sean Gross and Marilyne Labrie and Gordon Mills and Joe Gray and others},
doi = {10.1038/s42003-022-03218-x},
issn = {2399-3642},
issue = {1},
journal = {Communications Biology 2022 5:1},
keywords = {Breast cancer,Image processing},
month = {3},
pages = {1-10},
pmid = {35322205},
publisher = {Nature Publishing Group},
title = {A multi-encoder variational autoencoder controls multiple transformational features in single-cell image analysis},
volume = {5},
url = {https://www.nature.com/articles/s42003-022-03218-x},
year = {2022},
}


@article{Huang:2023a,
abstract = {The lack of annotated publicly available medical images is a major barrier for computational research and education innovations. At the same time, many de-identified images and much knowledge are shared by clinicians on public forums such as medical Twitter. Here we harness these crowd platforms to curate OpenPath, a large dataset of 208,414 pathology images paired with natural language descriptions. We demonstrate the value of this resource by developing pathology language-image pretraining (PLIP), a multimodal artificial intelligence with both image and text understanding, which is trained on OpenPath. PLIP achieves state-of-the-art performances for classifying new pathology images across four external datasets: for zero-shot classification, PLIP achieves F1 scores of 0.565-0.832 compared to F1 scores of 0.030-0.481 for previous contrastive language-image pretrained model. Training a simple supervised classifier on top of PLIP embeddings also achieves 2.5\% improvement in F1 scores compared to using other supervised model embeddings. Moreover, PLIP enables users to retrieve similar cases by either image or natural language search, greatly facilitating knowledge sharing. Our approach demonstrates that publicly shared medical information is a tremendous resource that can be harnessed to develop medical artificial intelligence for enhancing diagnosis, knowledge sharing and education.},
author = {Zhi Huang and Federico Bianchi and Mert Yuksekgonul and Thomas J. Montine and James Zou},
doi = {10.1038/s41591-023-02504-3},
issn = {1546170X},
issue = {9},
journal = {Nature Medicine},
month = {9},
pages = {2307-2316},
pmid = {37592105},
publisher = {Nature Research},
title = {A visual-language foundation model for pathology image analysis using medical Twitter},
volume = {29},
year = {2023},
}


@article{Wood:2023,
abstract = {Strong immune responses in primary colorectal cancer correspond with better patient survival following surgery compared with tumors with predominantly stromal microenvironments. However, biomarkers to identify patients with colorectal cancer liver metastases (CRLM) with good prognosis following surgery for oligometastatic disease remain elusive. The aim of this study was to determine the practical application of a simple histological assessment of immune cell infiltration and stromal content in predicting outcome following synchronous resection of primary colorectal cancer and CRLM and to interrogate the underlying functional biology that drives disease progression. Samples from patients undergoing synchronous resection of primary colorectal cancer and CRLM were evaluated in detail through histological assessment, panel genomic and bulk transcriptomic assessment, IHC, and GeoMx spatial transcriptomics (ST) analysis. High immune infiltration of metastases was associated with improved cancer-specific survival. Bulk transcriptomic analysis was confounded by stromal content, but ST demonstrated that the invasive edge of the metastases of long-term survivors was characterized by adaptive immune cell populations enriched for type II IFN signaling and MHC-class II antigen presentation. In contrast, patients with poor prognosis demonstrated increased abundance of regulatory T cells and neutrophils with enrichment of Notch and TGFb signaling pathways at the metastatic tumor center. In summary, histological assessment can stratify outcomes in patients undergoing synchronous resection of CRLM, suggesting that it has potential as a prognostic biomarker. Furthermore, ST analysis has revealed significant intratumoral and interlesional heterogeneity and identified the underlying transcriptomic programs driving each phenotype.},
author = {Colin S. Wood and Kathryn A.F. Pennel and Holly Leslie and Assya Legrini and Andrew J. Cameron and Lydia Melissourgou-Syka and others},
doi = {10.1158/0008-5472.CAN-22-2794},
issn = {0008-5472},
issue = {8},
journal = {Cancer Research},
month = {4},
pages = {1329-1344},
pmid = {37057593},
publisher = {American Association for Cancer Research},
title = {Spatially Resolved Transcriptomics Deconvolutes Prognostic Histological Subgroups in Patients with Colorectal Cancer and Synchronous Liver Metastases},
volume = {83},
year = {2023},
}


@article{Tippani:2023,
abstract = {Spatially resolved transcriptomics (SRT) is a growing field that links gene expression to anatomical context. SRT approaches that use next-generation sequencing (NGS) combine RNA sequencing with histological or fluorescent imaging to generate spatial maps of gene expression in intact tissue sections. These technologies directly couple gene expression measurements with high-resolution histological or immunofluorescent images that contain rich morphological information about the tissue under study. While broad access to NGS-based spatial transcriptomic technology is now commercially available through the Visium platform from the vendor 10× Genomics, computational tools for extracting image-derived metrics for integration with gene expression data remain limited. We developed VistoSeg as a MATLAB pipeline to process, analyze and interactively visualize the high-resolution images generated in the Visium platform. VistoSeg outputs can be easily integrated with accompanying transcriptomic data to facilitate downstream analyses in common programing languages including R and Python. VistoSeg provides user-friendly tools for integrating image-derived metrics from histological and immunofluorescent images with spatially resolved gene expression data. Integration of this data enhances the ability to understand the transcriptional landscape within tissue architecture. VistoSeg is freely available at http://research.libd.org/VistoSeg/.},
author = {Madhavi Tippani and Heena R. Divecha and Joseph L. Catallini and Sang H. Kwon and Lukas M. Weber and Abby Spangler and others},
doi = {10.1017/S2633903X23000235},
issn = {2633-903X},
journal = {Biological Imaging},
keywords = {MATLAB,Visium,Visium-Spatial Proteogenomics,hematoxylin and eosin,immunofluorescence,segmentation,spatially resolved transcriptomics},
pages = {e23},
publisher = {Cambridge University Press},
title = {VistoSeg: Processing utilities for high-resolution images for spatially resolved transcriptomics data},
volume = {3},
year = {2023},
}


@misc{TheCancerGenomeAtlasProgramTCGA--NCI,
author = {https://www.cancer.gov/ccg/research/genome-sequencing/tcga},
title = {The Cancer Genome Atlas Program (TCGA) -- NCI},
}


@article{Kaczmarzyk:2024,
abstract = {Digital pathology has seen a proliferation of deep learning models in recent years, but many models are not readily reusable. To address this challenge, we developed WSInfer: an open-source software ecosystem designed to streamline the sharing and reuse of deep learning models for digital pathology. The increased access to trained models can augment research on the diagnostic, prognostic, and predictive capabilities of digital pathology.},
author = {Jakub R. Kaczmarzyk and Alan O’Callaghan and Fiona Inglis and Swarad Gat and Tahsin Kurc and Rajarsi Gupta and others},
doi = {10.1038/s41698-024-00499-9},
issn = {2397768X},
issue = {1},
journal = {npj Precision Oncology},
month = {12},
publisher = {Nature Research},
title = {Open and reusable deep learning for pathology with WSInfer and QuPath},
volume = {8},
year = {2024},
}


@article{Pocock:2022,
abstract = {Computational pathology has seen rapid growth in recent years, driven by advanced deep-learning algorithms. Due to the sheer size and complexity of multi-gigapixel whole-slide images, to the best of our knowledge, there is no open-source software library providing a generic end-to-end API for pathology image analysis using best practices. Most researchers have designed custom pipelines from the bottom up, restricting the development of advanced algorithms to specialist users. To help overcome this bottleneck, we present TIAToolbox, a Python toolbox designed to make computational pathology accessible to computational, biomedical, and clinical researchers. By creating modular and configurable components, we enable the implementation of computational pathology algorithms in a way that is easy to use, flexible and extensible. We consider common sub-tasks including reading whole slide image data, patch extraction, stain normalization and augmentation, model inference, and visualization. For each of these steps, we provide a user-friendly application programming interface for commonly used methods and models. We demonstrate the use of the interface to construct a full computational pathology deep-learning pipeline. We show, with the help of examples, how state-of-the-art deep-learning algorithms can be reimplemented in a streamlined manner using our library with minimal effort. We provide a usable and adaptable library with efficient, cutting-edge, and unit-tested tools for data loading, pre-processing, model inference, post-processing, and visualization. This enables a range of users to easily build upon recent deep-learning developments in the computational pathology literature. Computational software is being introduced to pathology, the study of the causes and effects of disease. Recently various computational pathology algorithms have been developed to analyze digital histology images. However, the software code written for these algorithms often combines functionality from several software packages which have specific setup requirements and code styles. This makes it difficult to re-use this code in other projects. We developed a computational software named TIAToolbox to alleviate this problem and hope this will help accelerate the use of computational software in pathology. Pocock, Graham et al. present TIAToolbox, a Python toolbox for computational pathology. The extendable library can be used for data loading, pre-processing, model inference, post-processing, and visualization.},
author = {Johnathan Pocock and Simon Graham and Quoc Dang Vu and Mostafa Jahanifar and Srijay Deshpande and Giorgos Hadjigeorghiou and others},
doi = {10.1038/s43856-022-00186-5},
issn = {2730-664X},
issue = {1},
journal = {Communications Medicine 2022 2:1},
keywords = {Cancer imaging,Computational biology and bioinformatics},
month = {9},
pages = {1-14},
publisher = {Nature Publishing Group},
title = {TIAToolbox as an end-to-end library for advanced tissue image analytics},
volume = {2},
year = {2022},
}


@article{Cardoso:2022,
abstract = {Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.},
author = {M. Jorge Cardoso and Wenqi Li and Richard Brown and Nic Ma and Eric Kerfoot and Yiheng Wang and others},
journal = {arXiv:2211.02701},
month = {11},
title = {MONAI: An open-source framework for deep learning in healthcare},
year = {2022},
}


@article{Dolezal:2024,
abstract = {Deep learning methods have emerged as powerful tools for analyzing histopathological images, but current methods are often specialized for specific domains and software environments, and few open-source options exist for deploying models in an interactive interface. Experimenting with different deep learning approaches typically requires switching software libraries and reprocessing data, reducing the feasibility and practicality of experimenting with new architectures. We developed a flexible deep learning library for histopathology called Slideflow, a package which supports a broad array of deep learning methods for digital pathology and includes a fast whole-slide interface for deploying trained models. Slideflow includes unique tools for whole-slide image data processing, efficient stain normalization and augmentation, weakly-supervised whole-slide classification, uncertainty quantification, feature generation, feature space analysis, and explainability. Whole-slide image processing is highly optimized, enabling whole-slide tile extraction at 40x magnification in 2.5 s per slide. The framework-agnostic data processing pipeline enables rapid experimentation with new methods built with either Tensorflow or PyTorch, and the graphical user interface supports real-time visualization of slides, predictions, heatmaps, and feature space characteristics on a variety of hardware devices, including ARM-based devices such as the Raspberry Pi.},
author = {James M. Dolezal and Sara Kochanny and Emma Dyer and Siddhi Ramesh and Andrew Srisuwananukorn and Matteo Sacco and others},
doi = {10.1186/S12859-024-05758-X/FIGURES/15},
issn = {14712105},
issue = {1},
journal = {BMC Bioinformatics},
keywords = {Computational pathology,Digital pathology,Explainable AI,Self-supervised learning,Software toolkit,Whole-slide imaging},
month = {12},
pages = {1-29},
pmid = {38539070},
publisher = {BioMed Central Ltd},
title = {Slideflow: deep learning for digital histopathology with real-time whole-slide visualization},
volume = {25},
year = {2024},
}


@article{Faust:2024,
abstract = {Deep learning has proven to be capable of automating key aspects of histopathologic analysis, but its continual reliance on large expert-annotated training datasets hinders widespread adoption. Here, we present an online collaborative portal that streamlines tissue image annotation to promote the development and sharing of custom computer vision models for PHenotyping And Regional Analysis Of Histology (PHARAOH; <https://www.pathologyreports.ai/>). PHARAOH uses a weakly supervised active learning framework whereby patch-level image features are leveraged to organize large swaths of tissue into morphologically-uniform clusters for batched human annotation. By providing cluster-level labels on only a handful of cases, we show how custom PHARAOH models can be developed and used to guide the quantification of cellular features that correlate with molecular, pathologic and patient outcome data. Both custom model design and feature extraction pipelines are amenable to crowdsourcing making PHARAOH a fully scalable systems-level solution for the systematic expansion and cataloging of computational pathology applications. 
 
### Competing Interest Statement 
 
The authors have declared no competing interest.},
author = {Kevin Faust and Min Li Chen and Parsa Babaei Zadeh and Dimitrios Oreopoulos and Alberto J. Leon and Evelyn Rose Kamski-Hennekam and others},
doi = {10.1101/2024.03.20.585977},
journal = {bioRxiv},
keywords = {Crowdsourcing,automation,convolutional neural networks,deep learning,pathology},
month = {3},
pages = {2024.03.20.585977},
publisher = {Cold Spring Harbor Laboratory},
title = {PHARAOH: A collaborative crowdsourcing platform for PHenotyping And Regional Analysis Of Histology},
year = {2024},
}


@article{Dieci:2018,
abstract = {Morphological evaluation of tumor-infiltrating lymphocytes (TILs) in breast cancer is gaining momentum as evidence strengthens the clinical relevance of this immunological biomarker. TILs in the post-neoadjuvant residual disease setting are acquiring increasing importance as a stratifying marker in clinical trials, considering the raising interest on immunotherapeutic strategies after neoadjuvant chemotherapy. TILs in ductal carcinoma in situ, with or without invasive carcinoma, represent an emerging area of clinical breast cancer research. The aim of this report is to update pathologists, clinicians and researchers on TIL assessment in both the post-neoadjuvant residual disease and the ductal carcinoma in situ settings. The International Immuno-Oncology Working Group proposes a method for assessing TILs in these settings, based on the previously published International Guidelines on TIL Assessment in Breast Cancer. In this regard, these recommendations represent a consensus guidance for pathologists, aimed to achieve the highest possible consistency among future studies.},
author = {Maria Vittoria Dieci and Nina Radosevic-Robin and Susan Fineberg and Gert van den Eynden and Nils Ternes and Frederique Penault-Llorca and others},
doi = {10.1016/J.SEMCANCER.2017.10.003},
issn = {1044-579X},
journal = {Seminars in Cancer Biology},
keywords = {Breast cancer,Ductal carcinoma in situ,Neoadjuvant,Residual cancer burden,Residual disease,Tumor-infiltrating lymphocytes},
month = {10},
pages = {16-25},
pmid = {29024776},
publisher = {Academic Press},
title = {Update on tumor-infiltrating lymphocytes (TILs) in breast cancer, including recommendations to assess TILs in residual disease after neoadjuvant therapy and in carcinoma in situ: A report of the International Immuno-Oncology Biomarker Working Group on Breast Cancer},
volume = {52},
year = {2018},
}


@article{Kuchenhoff:2023,
abstract = {Local cell densities and positioning within cellular monolayers and stratified epithelia have important implications for cell interactions and the functionality of various biological processes. To analyze the relationship between cell localization and tissue physiology, density-based clustering algorithms, such as DBSCAN, allow for a detailed characterization of the spatial distribution and positioning of individual cells. However, these methods rely on predefined parameters that influence the outcome of the analysis. With varying cell densities in cell cultures or tissues impacting cell sizes and, thus, cellular proximities, these parameters need to be carefully chosen. In addition, standard DBSCAN approaches generally come short in appropriately identifying individual cell positions. We therefore developed three extensions to the standard DBSCAN-algorithm that provide: (i) an automated parameter identification to reliably identify cell clusters, (ii) an improved identification of cluster edges; and (iii) an improved characterization of the relative positioning of cells within clusters. We apply our novel methods, which are provided as a user-friendly OpenSource-software package (DBSCAN-CellX), to cellular monolayers of different cell lines. Thereby, we show the importance of the developed extensions for the appropriate analysis of cell culture experiments to determine the relationship between cell localization and tissue physiology.},
author = {Leonie K\"{u}chenhoff and Pascal Lukas and Camila Metz-Zumaran and Paul Rothhaar and Alessia Ruggieri and Volker Lohmann and others},
doi = {10.1038/s41598-023-45190-4},
isbn = {0123456789},
issn = {2045-2322},
issue = {1},
journal = {Scientific Reports 2023 13:1},
keywords = {Cell biology,Computational biology and bioinformatics,Systems biology},
month = {11},
pages = {1-11},
pmid = {37914751},
publisher = {Nature Publishing Group},
title = {Extended methods for spatial cell classification with DBSCAN-CellX},
volume = {13},
year = {2023},
}


@inproceedings{Ester:1996,
abstract = {Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by factor of more than 100 in terms of efficiency.},
author = {Martin Ester and Hans-Peter Kriegel and Jiirg Sander and Xiaowei Xu},
editor = {Evangelos Simoudis and Jiawei Han and Usama M. Fayyad},
isbn = {1-57735-004-9},
journal = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining (KDD-96)},
keywords = {Arbitrary Shape of Clus-ters,Clustering Algorithms,Efficiency on Large Spatial Databases,Handling Nlj4-275oise},
pages = {226-231},
publisher = {AAAI Press.},
title = {A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise},
year = {1996},
}


@article{Shao:2021,
abstract = {Cell-cell communications in multicellular organisms generally involve secreted ligand-receptor (LR) interactions, which is vital for various biological phenomena. Recent advancements in single-cell RNA sequencing (scRNA-seq) have effectively resolved cellular phenotypic heterogeneity and the cell-type composition of complex tissues, facilitating the systematic investigation of cell-cell communications at single-cell resolution. However, assessment of chemical-signal-dependent cell-cell communication through scRNA-seq relies heavily on prior knowledge of LR interaction pairs. We constructed CellTalkDB (http://tcm.zju.edu.cn/celltalkdb), a manually curated comprehensive database of LR interaction pairs in humans and mice comprising 3398 human LR pairs and 2033 mouse LR pairs, through text mining and manual verification of known protein-protein interactions using the STRING database, with literature-supported evidence for each pair. Compared with SingleCellSignalR, the largest LR-pair resource, CellTalkDB includes not only 2033 mouse LR pairs but also 377 additional human LR pairs. In conclusion, the data on human and mouse LR pairs contained in CellTalkDB could help to further the inference and understanding of the LR-interaction-based cell-cell communications, which might provide new insights into the mechanism underlying biological processes.},
author = {Xin Shao and Jie Liao and Chengyu Li and Xiaoyan Lu and Junyun Cheng and Xiaohui Fan},
doi = {10.1093/BIB/BBAA269},
issn = {1477-4054},
issue = {4},
journal = {Briefings in bioinformatics},
keywords = {Animals,Cell Communication*,Cell Surface / metabolism*,Databases,Factual*,Humans,Jie Liao,Ligands,MEDLINE,Mice,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,PubMed Abstract,RNA-Seq*,Receptors,Research Support,Single-Cell Analysis*,Xiaohui Fan,Xin Shao,doi:10.1093/bib/bbaa269,pmid:33147626},
month = {7},
pmid = {33147626},
publisher = {Brief Bioinform},
title = {CellTalkDB: a manually curated database of ligand-receptor interactions in humans and mice},
volume = {22},
year = {2021},
}


@article{Liu:2022,
abstract = {Background: Cell-cell interactions are important for information exchange between different cells, which are the fundamental basis of many biological processes. Recent advances in single-cell RNA sequencing (scRNA-seq) enable the characterization of cell-cell interactions using computational methods. However, it is hard to evaluate these methods since no ground truth is provided. Spatial transcriptomics (ST) data profiles the relative position of different cells. We propose that the spatial distance suggests the interaction tendency of different cell types, thus could be used for evaluating cell-cell interaction tools. Results: We benchmark 16 cell-cell interaction methods by integrating scRNA-seq with ST data. We characterize cell-cell interactions into short-range and long-range interactions using spatial distance distributions between ligands and receptors. Based on this classification, we define the distance enrichment score and apply an evaluation workflow to 16 cell-cell interaction tools using 15 simulated and 5 real scRNA-seq and ST datasets. We also compare the consistency of the results from single tools with the commonly identified interactions. Our results suggest that the interactions predicted by different tools are highly dynamic, and the statistical-based methods show overall better performance than network-based methods and ST-based methods. Conclusions: Our study presents a comprehensive evaluation of cell-cell interaction tools for scRNA-seq. CellChat, CellPhoneDB, NicheNet, and ICELLNET show overall better performance than other tools in terms of consistency with spatial tendency and software scalability. We recommend using results from at least two methods to ensure the accuracy of identified interactions. We have packaged the benchmark workflow with detailed documentation at GitHub (https://github.com/wanglabtongji/CCI).},
author = {Zhaoyang Liu and Dongqing Sun and Chenfei Wang},
doi = {10.1186/S13059-022-02783-Y/FIGURES/9},
issn = {1474760X},
issue = {1},
journal = {Genome Biology},
keywords = {Benchmarking,Cell-cell interaction,Spatial interaction tendency,Spatial transcriptomics,scRNA-seq},
month = {12},
pages = {1-38},
pmid = {36253792},
publisher = {BioMed Central Ltd},
title = {Evaluation of cell-cell interaction methods by integrating single-cell RNA sequencing data with spatial information},
volume = {23},
year = {2022},
}


@article{Schindelin:2012,
abstract = {Presented is an overview of the image-analysis software platform Fiji, a distribution of ImageJ that updates the underlying ImageJ architecture and adds modern software design elements to expand the capabilities of the platform and facilitate collaboration between biologists and computer scientists. Fiji is a distribution of the popular open-source software ImageJ focused on biological-image analysis. Fiji uses modern software engineering practices to combine powerful software libraries with a broad range of scripting languages to enable rapid prototyping of image-processing algorithms. Fiji facilitates the transformation of new algorithms into ImageJ plugins that can be shared with end users through an integrated update system. We propose Fiji as a platform for productive collaboration between computer science and biology research communities.},
author = {Johannes Schindelin and Ignacio Arganda-Carreras and Erwin Frise and Verena Kaynig and Mark Longair and Tobias Pietzsch and others},
doi = {10.1038/nmeth.2019},
issn = {1548-7105},
issue = {7},
journal = {Nature Methods},
keywords = {Imaging,Software},
month = {6},
pages = {676-682},
pmid = {22743772},
publisher = {Nature Publishing Group},
title = {Fiji: an open-source platform for biological-image analysis},
volume = {9},
year = {2012},
}


@misc{H&EtoXeniumDAPIImageRegistrationwithFiji--10xGenomics,
author = {10x~Genomics},
title = {H\&E to Xenium DAPI Image Registration with Fiji -- 10x Genomics},
url = {https://www.10xgenomics.com/analysis-guides/he-to-xenium-dapi-image-registration-with-fiji},
}


@inproceedings{Huang:2023b,
abstract = {In situ RNA capturing represents an excellent opportunity for bridging transcriptomic data to a spatial domain, making it possible to map the gene expression to the corresponding anatomical structure. As a result, scientists can better understand the transcriptional heterogeneity with spatially resolved, anatomical, and pathophysiological contexts. However, high throughput sequencing technologies paired with histological images suffer from lower resolution mapping between transcriptome and imaging data. Here, we present Spatial Transcriptome Auto-encoder and Deconvolution (ST-AnD), a scalable deep generative model for predicting gene expression at cellular or nuclei level based on H\&amp;E imaging and in situ RNA capturing, thus allowing a better understanding of the tissue microenvironment.},
author = {Chao-Hui Huang and Yoson Park and Jincheng Pang and Jadwiga R. Bienkowska},
doi = {10.1117/12.2654294},
isbn = {9781510660472},
issn = {16057422},
journal = {SPIE Medical Imaging 2023: Digital and Computational Pathology},
keywords = {Data modeling,Genomics,Machine learning,Spatial resolution,Tumors},
month = {4},
pages = {17-25},
publisher = {SPIE},
title = {Single-cell gene expression prediction using H\&E images based on spatial transcriptomics},
volume = {12471},
year = {2023},
}


@article{Ji:2024,
abstract = {Drawing parallels between linguistic constructs and cellular biology, large language models (LLMs) have achieved remarkable success in diverse downstream applications for single-cell data analysis. However, to date, it still lacks methods to take advantage of LLMs to infer ligand-receptor (LR)-mediated cell-cell communications for spatially resolved transcriptomic data. Here, we propose SpaCCC to facilitate the inference of spatially resolved cell-cell communications, which relies on our fine-tuned single-cell LLM and functional gene interaction network to embed ligand and receptor genes expressed in interacting individual cells into a unified latent space. The LR pairs with a significant closer distance in latent space are taken to be more likely to interact with each other. After that, the molecular diffusion and permutation test strategies are respectively employed to calculate the communication strength and filter out communications with low specificities. The benchmarked performance of SpaCCC is evaluated on real single-cell spatial transcriptomic datasets with remarkable superiority over other methods. SpaCCC also infers known LR pairs concealed by existing aggregative methods and then identifies communication patterns for specific cell types and their signalling pathways. Furthermore, spaCCC provides various cell-cell communication visualization results at both single-cell and cell type resolution. In summary, spaCCC provides a sophisticated and practical tool allowing researchers to decipher spatially resolved cell-cell communications and related communication patterns and signalling pathways based on spatial transcriptome data. 
 
### Competing Interest Statement 
 
The authors have declared no competing interest.},
author = {Boya Ji and Liwen Xu and Shaoliang Peng},
doi = {10.1101/2024.02.21.581369},
journal = {bioRxiv},
month = {2},
pages = {2024.02.21.581369},
publisher = {Cold Spring Harbor Laboratory},
title = {SpaCCC: Large language model-based cell-cell communication inference for spatially resolved transcriptomic data},
year = {2024},
}


@article{Huang:2024,
abstract = {Recently, various technologies have been introduced into digital pathology, including artificial intelligence (AI) driven methods, in both areas of pathological whole slide image (WSI) analysis and spatial transcriptomics (ST) analysis. AI-driven WSI analysis utilizes the power of deep learning (DL), expands the field of view for histopathological image analysis. On the other hand, ST bridges the gap between tissue spatial analysis and biological signals, offering the possibility to understand the spatial biology. However, a major bottleneck in DL-based WSI analysis is the preparation of training patterns, as hematoxylin \& eosin (H\&E) staining does not provide direct biological evidence, such as gene expression, for determining the category of a biological component. On the other hand, as of now, the resolution in ST is far beyond that of WSI, resulting the challenge of further spatial analysis. Although various WSI analysis tools, including QuPath, have cited the use of WSI analysis tools in the context of ST analysis, its usage is primarily focused on initial image analysis, with other tools being utilized for more detailed transcriptomic analysis. As a result, the information hidden beneath WSI has not yet been fully utilized to support ST analysis. To bridge this gap, we introduce QuST, a QuPath extension designed to bridge the gap between H\&E WSI and ST analyzing tasks. In this paper, we highlight the importance of integrating DL-based WSI analysis and ST analysis in understanding disease biology and the challenges in integrating these modalities due to differences in data formats and analytical methods. The QuST source code is hosted on GitHub and documentation is available at https://github.com/huangch/qust.},
author = {Chao-Hui Huang},
journal = {arXiv:2406.01613 [q-bio.QM]},
keywords = {Path extension,Qu},
month = {5},
title = {QuST: QuPath Extension for Integrative Whole Slide Image and Spatial Transcriptomics Analysis},
url = {https://arxiv.org/abs/2406.01613},
year = {2024},
}


@article{Wolf:2018,
abstract = {Scanpy is a scalable toolkit for analyzing single-cell gene expression data. It includes methods for preprocessing, visualization, clustering, pseudotime and trajectory inference, differential expression testing, and simulation of gene regulatory networks. Its Python-based implementation efficiently deals with data sets of more than one million cells ( https://github.com/theislab/Scanpy ). Along with Scanpy, we present AnnData, a generic class for handling annotated data matrices ( https://github.com/theislab/anndata ).},
author = {F. Alexander Wolf and Philipp Angerer and Fabian J. Theis},
doi = {10.1186/S13059-017-1382-0/FIGURES/1},
issn = {1474760X},
issue = {1},
journal = {Genome Biology},
keywords = {Bioinformatics,Clustering,Differential expression testing,Graph analysis,Machine learning,Pseudotemporal ordering,Scalability,Single-cell transcriptomics,Trajectory inference,Visualization},
month = {2},
pages = {1-5},
pmid = {29409532},
publisher = {BioMed Central Ltd.},
title = {SCANPY: Large-scale single-cell gene expression data analysis},
volume = {19},
year = {2018},
}


@article{Klopfenstein:2018,
abstract = {The biological interpretation of gene lists with interesting shared properties, such as up- or down-regulation in a particular experiment, is typically accomplished using gene ontology enrichment analysis tools. Given a list of genes, a gene ontology (GO) enrichment analysis may return hundreds of statistically significant GO results in a “flat” list, which can be challenging to summarize. It can also be difficult to keep pace with rapidly expanding biological knowledge, which often results in daily changes to any of the over 47,000 gene ontologies that describe biological knowledge. GOATOOLS, a Python-based library, makes it more efficient to stay current with the latest ontologies and annotations, perform gene ontology enrichment analyses to determine over- and under-represented terms, and organize results for greater clarity and easier interpretation using a novel GOATOOLS GO grouping method. We performed functional analyses on both stochastic simulation data and real data from a published RNA-seq study to compare the enrichment results from GOATOOLS to two other popular tools: DAVID and GOstats. GOATOOLS is freely available through GitHub: https://github.com/tanghaibao/goatools .},
author = {D. V. Klopfenstein and Liangsheng Zhang and Brent S. Pedersen and Fidel Ram\'{i}rez and Alex Warwick Vesztrocy and Aur\'{e}lien Naldi and others},
doi = {10.1038/s41598-018-28948-z},
issn = {2045-2322},
issue = {1},
journal = {Scientific Reports 2018 8:1},
keywords = {Gene ontology,Software},
month = {7},
pages = {1-17},
pmid = {30022098},
publisher = {Nature Publishing Group},
title = {GOATOOLS: A Python library for Gene Ontology analyses},
volume = {8},
year = {2018},
}


@article{NatureMethods:2021,
abstract = {Spatially resolved transcriptomics methods are changing the way we understand complex tissues.},
doi = {10.1038/s41592-020-01042-x},
isbn = {4159202001042x},
issn = {1548-7105},
issue = {1},
author = {{Nature Methods}},
journal = {Nature Methods},
keywords = {Fluorescence in situ hybridization,Gene expression profiling,Genomics,RNA sequencing},
month = {1},
pmid = {33408396},
publisher = {Nature Publishing Group},
title = {Method of the Year 2020: spatially resolved transcriptomics},
volume = {18},
year = {2021},
}


@article{Wang:2024,
abstract = {The field of single-cell transcriptomics has been producing extensive datasets, advancing our understanding of cellular functions in various tissues, and empowering diagnosis, prognosis, and drug development. However, parsing through this data has been a monumental task, often stretching weeks to months. This bottleneck arises due to the sheer volume of data generated—ranging from hundreds of gigabytes to tens of terabytes—that demands extensive time for analysis. Moreover, the data analysis involves an intricate series of steps utilizing various software packages, creating a steep learning curve for biologists. Additionally, the iterative nature of data analysis in this domain necessitates a deep biological insight to formulate relevant questions, conduct analysis, interpret results, and refine hypotheses. This iterative loop has required close collaboration between biologists and bioinformaticians, which is hampered by protracted communication cycles. To address these challenges, we present a large language model-powered software, Bioinformatics Copilot 1.0. It allows users to analyze data through an intuitive natural language interface, without requiring proficiency in programming languages such as Python or R. It is engineered for cross-platform functionality, with support for Mac, Windows, and Linux. Importantly, it facilitates local data analysis, ensuring adherence to stringent data management regulations that govern the use of patient samples in medical and research institutions. We anticipate that this tool will expedite the data analysis workflow in numerous research endeavors, thereby accelerating advancements in the biomedical sciences. 
 
### Competing Interest Statement 
 
The authors have declared no competing interest.},
author = {Yongheng Wang and Weidi Zhang and Siyu Lin and Matthew S. Farruggio and Aijun Wang},
doi = {10.1101/2024.04.11.588958},
journal = {bioRxiv},
month = {4},
publisher = {Cold Spring Harbor Laboratory},
title = {Bioinformatics Copilot 1.0: A Large Language Model-powered Software for the Analysis of Transcriptomic Data},
volume = {2024.04.11.588958},
year = {2024},
}


@article{Luo:2024,
abstract = {Spatially resolved omics technologies generating multimodal and high-throughput data lead to the urgent need for advanced analysis to allow the biological discoveries by comprehensively utilizing information from multi-omics data. The H\&E image and spatial transcriptomic data indicate abundant features which are different and complementary to each other. AI algorithms can perform nonlinear analysis on these aligned or unaligned complex datasets to decode tumoral heterogeneity for detecting functional domain. However,the interpretability of AI-generated outcomes for human experts is a problem hindering application of multi-modal analysis in clinic. We presented a machine learning based toolchain called StereoMM, which is a graph fusion model that can integrate gene expression, histological images, and spatial location. StereoMM firstly performs information interaction on transcriptomic and imaging features through the attention module, guaranteeing explanations for its decision-making processes. The interactive features are input into the graph autoencoder together with the graph of spatial position, so that multimodal features are fused in a self-supervised manner. Here, StereoMM was subjected to mouse brain tissue, demonstrating its capability to discern fine tissue architecture, while highlighting its advantage in computational speed. Utilizing data from Stereo-seq of human lung adenosquamous carcinoma and 10X Visium of human breast cancer, we showed its superior performance in spatial domain recognition over competing software and its ability to reveal tumor heterogeneity. The fusion approach for imaging and gene expression data within StereoMM aids in the more accurate identification of domains, unveils critical molecular features, and elucidates the connections between different domains, thereby laying the groundwork for downstream analysis. 
 
### Competing Interest Statement 
 
The authors have declared no competing interest.},
author = {Bingying Luo and Fei Teng and Guo Tang and Weixuan Chen and Chi Qu and Xuanzhu Liu and others},
doi = {10.1101/2024.05.04.592486},
journal = {bioRxiv},
month = {5},
publisher = {Cold Spring Harbor Laboratory},
title = {StereoMM: A Graph Fusion Model for Integrating Spatial Transcriptomic Data and Pathological Images},
volume = {2024.05.04.592486},
year = {2024},
}


@article{Lowe:2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
author = {David G. Lowe},
doi = {10.1023/B:VISI.0000029664.99615.94/METRICS},
issn = {09205691},
issue = {2},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
month = {11},
pages = {91-110},
publisher = {Springer},
title = {Distinctive image features from scale-invariant keypoints},
volume = {60},
year = {2004},
}


